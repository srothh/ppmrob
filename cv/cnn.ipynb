{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:01:07.103001Z",
     "start_time": "2024-01-23T14:01:05.791982700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:28:53.871747500Z",
     "start_time": "2024-01-23T13:28:53.864748400Z"
    }
   },
   "id": "e0056f016dbd1df8",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 1 - Prepare data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eeab916d55c87e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data is loaded from a video and split into frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b214a1d20ede5f9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transformation = transform.Compose([\n",
    "    transform.Resize((64, 64)),\n",
    "    transform.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:01:16.789498200Z",
     "start_time": "2024-01-23T14:01:16.746289500Z"
    }
   },
   "id": "890ca8e113a4470f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \"./dataset\"\n",
    "dataset = ImageFolder(root=data_dir, transform=transformation)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "img, l = None, None\n",
    "for images, labels in data_loader:\n",
    "    img, l = images[0], labels[0]\n",
    "    break\n",
    "img_test = img.permute(1, 2, 0).numpy()\n",
    "plt.imshow(img_test)\n",
    "plt.title(f\"Label: {l}\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:16:09.935576300Z",
     "start_time": "2024-01-23T14:16:09.223799100Z"
    }
   },
   "id": "151530569521fd6d",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ef73a014c644bac6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 64])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:16:11.817148200Z",
     "start_time": "2024-01-23T14:16:11.814147600Z"
    }
   },
   "id": "d22a13f8b90b0ed9",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "test_len = 0.2\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:43:18.709670200Z",
     "start_time": "2024-01-23T14:43:18.703668700Z"
    }
   },
   "id": "681f023702adb483",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int((1-test_len) * len(dataset))\n",
    "test_size = int(test_len * len(dataset))\n",
    "extra = len(dataset) - (train_size + test_size)\n",
    "train_size = train_size + extra if extra > 0 else train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False) # no need to shuffle test data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:43:16.127275800Z",
     "start_time": "2024-01-23T14:43:16.124275800Z"
    }
   },
   "id": "9b8b8b6afcd68890",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define NN\n",
    "from torch import nn\n",
    "\n",
    "class VictimCNNModelV0(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_units, output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units*16*16,\n",
    "                out_features=output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:45:38.587551Z",
     "start_time": "2024-01-23T14:45:38.579551600Z"
    }
   },
   "id": "64af8d04e2dc80af",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:55:07.092582500Z",
     "start_time": "2024-01-23T14:55:07.088582500Z"
    }
   },
   "id": "4e1f82ff1a54fe04",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = VictimCNNModelV0(3, 32, 1).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:45:40.219604100Z",
     "start_time": "2024-01-23T14:45:40.204602700Z"
    }
   },
   "id": "f997ae76db52b39b",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('conv1.0.weight',\n              tensor([[[[ 1.6033e-01, -1.7340e-01,  1.2968e-01],\n                        [-1.2204e-01, -3.6341e-02,  1.2403e-01],\n                        [ 5.7834e-02,  1.7840e-01,  3.5821e-02]],\n              \n                       [[-5.7579e-02,  5.3255e-02, -9.7742e-02],\n                        [-1.9044e-01,  1.7892e-01, -7.9669e-02],\n                        [-3.9279e-02, -1.5045e-01,  2.3700e-02]],\n              \n                       [[-2.1005e-02,  2.3590e-03, -1.3560e-01],\n                        [ 1.5779e-01,  1.5081e-01,  1.6878e-01],\n                        [ 1.5745e-01,  1.1303e-01,  1.9092e-01]]],\n              \n              \n                      [[[-1.1220e-01, -1.7875e-02, -1.7101e-01],\n                        [ 2.8471e-02, -9.7050e-02,  1.3545e-02],\n                        [-8.3213e-02,  1.4303e-01, -2.1494e-02]],\n              \n                       [[ 1.4548e-01,  1.6819e-01, -1.5244e-01],\n                        [-1.2398e-01, -1.0832e-01,  8.5666e-02],\n                        [-1.3144e-01, -1.3076e-01, -1.1898e-01]],\n              \n                       [[-1.1634e-01,  7.3887e-02, -1.8225e-01],\n                        [-1.2231e-01,  6.0430e-02,  1.5642e-01],\n                        [-1.9150e-01,  8.5763e-02,  7.0444e-02]]],\n              \n              \n                      [[[ 9.4881e-02, -5.5579e-02,  1.3036e-01],\n                        [-1.0890e-01,  3.8951e-02,  6.8009e-02],\n                        [-1.1939e-01,  1.7797e-01,  2.9509e-02]],\n              \n                       [[ 7.4167e-02, -8.4389e-02,  1.9124e-01],\n                        [-1.5703e-01, -1.0070e-01,  9.1735e-02],\n                        [ 4.8487e-02,  1.2125e-01, -1.6838e-01]],\n              \n                       [[-9.0041e-02,  5.7423e-03,  3.7583e-02],\n                        [-3.9240e-02, -2.7111e-02, -5.2583e-02],\n                        [ 1.1319e-01,  5.7449e-02,  7.8238e-02]]],\n              \n              \n                      [[[ 6.1463e-02, -1.8101e-01,  1.1178e-01],\n                        [ 1.6593e-01,  1.9096e-01,  3.8726e-02],\n                        [-9.2158e-02,  4.7575e-02, -1.1276e-01]],\n              \n                       [[-9.9782e-02,  6.2453e-02, -1.6431e-02],\n                        [-5.1917e-04, -2.6058e-02, -8.9881e-03],\n                        [ 2.6427e-02, -8.4464e-03,  3.0251e-02]],\n              \n                       [[-2.9383e-02, -1.4002e-01, -1.2271e-01],\n                        [-1.0144e-01,  1.3871e-01, -5.2098e-02],\n                        [ 3.0073e-02,  2.6750e-02, -8.8590e-02]]],\n              \n              \n                      [[[-1.3342e-01, -9.0428e-02, -1.1501e-01],\n                        [-6.9437e-03,  1.1299e-01, -6.8963e-02],\n                        [-1.3182e-01, -2.0417e-02, -5.6142e-02]],\n              \n                       [[ 2.7180e-02, -4.0463e-03, -1.4249e-01],\n                        [-1.5367e-01,  9.1766e-02,  8.9619e-02],\n                        [-7.6064e-02,  2.8148e-02,  5.5817e-02]],\n              \n                       [[ 1.3542e-01,  7.2540e-02, -7.0348e-02],\n                        [-5.1294e-02, -4.0829e-02,  1.2689e-01],\n                        [-9.9470e-02,  1.4425e-01, -1.1520e-01]]],\n              \n              \n                      [[[ 6.3819e-02,  5.9394e-03, -9.2123e-02],\n                        [ 7.3003e-02, -8.5971e-02, -1.3425e-01],\n                        [-3.9113e-02, -1.6661e-01,  1.4400e-01]],\n              \n                       [[-3.8143e-02, -6.0300e-04,  2.3121e-02],\n                        [-7.4621e-02,  1.0012e-01,  1.3264e-02],\n                        [-1.6011e-01,  4.3064e-02, -9.9669e-02]],\n              \n                       [[ 1.7137e-01, -1.6090e-02,  1.4998e-01],\n                        [ 1.6612e-01,  3.4003e-02, -4.7179e-02],\n                        [ 1.6336e-01, -4.3375e-02, -1.1436e-01]]],\n              \n              \n                      [[[ 1.9079e-01, -4.0747e-02,  3.1297e-02],\n                        [-2.8429e-02,  2.5360e-02,  6.6166e-02],\n                        [-1.2650e-01,  1.3451e-02, -6.3306e-02]],\n              \n                       [[ 1.9356e-03, -6.2538e-02,  1.8608e-02],\n                        [-8.4234e-02, -1.2676e-01, -3.3549e-02],\n                        [ 1.1357e-01, -1.4592e-01,  1.0402e-01]],\n              \n                       [[-6.9396e-02,  1.0878e-01, -9.7182e-02],\n                        [-1.5587e-01, -2.5556e-02, -6.0061e-02],\n                        [-4.7865e-02,  2.9935e-02,  3.7025e-02]]],\n              \n              \n                      [[[ 4.3419e-02,  1.3474e-01,  1.5814e-01],\n                        [-9.1412e-02, -5.2913e-02,  8.5140e-03],\n                        [-2.6972e-02,  3.5081e-03,  1.4340e-01]],\n              \n                       [[ 5.4065e-02, -1.3012e-01, -1.3324e-01],\n                        [-1.8504e-01,  1.4245e-01, -1.6816e-02],\n                        [ 1.2214e-01, -1.0643e-01, -1.8665e-01]],\n              \n                       [[ 4.7656e-02, -1.8508e-01, -1.0025e-01],\n                        [-2.0191e-02,  1.5621e-01,  2.2624e-02],\n                        [-6.6785e-02,  1.3563e-01,  6.2272e-02]]],\n              \n              \n                      [[[-4.8393e-02,  1.2140e-01,  5.6047e-02],\n                        [-3.5916e-02, -3.1051e-03, -6.2252e-02],\n                        [-3.1419e-02, -1.1113e-01,  1.5200e-01]],\n              \n                       [[-1.1792e-01, -1.1915e-01, -1.2938e-01],\n                        [ 1.8485e-01, -6.5137e-02, -3.5864e-02],\n                        [ 1.6672e-01, -1.4181e-01, -1.7332e-01]],\n              \n                       [[-1.0515e-01, -3.9365e-03, -1.1444e-01],\n                        [ 6.1720e-02, -7.1363e-02,  4.1725e-02],\n                        [ 1.6494e-02,  1.3789e-01, -5.8114e-02]]],\n              \n              \n                      [[[ 4.7170e-02, -8.2258e-02,  6.2394e-02],\n                        [ 1.4269e-01,  3.9509e-02, -6.0342e-02],\n                        [-1.2021e-02,  1.0131e-01,  1.0763e-01]],\n              \n                       [[ 1.5365e-01, -1.2824e-01, -4.0926e-02],\n                        [-1.1018e-01,  1.6262e-01,  4.4486e-02],\n                        [-1.7686e-01, -1.4774e-01,  1.0164e-01]],\n              \n                       [[ 1.6409e-01, -5.2047e-02,  2.3971e-02],\n                        [-5.2764e-02, -1.4483e-01,  8.5915e-02],\n                        [-9.3225e-02, -3.8005e-02,  1.1773e-01]]],\n              \n              \n                      [[[ 1.5785e-01,  1.4898e-01,  6.8922e-02],\n                        [-1.2739e-01, -5.4623e-02,  9.4068e-02],\n                        [-9.4632e-02, -4.8308e-02, -1.9045e-02]],\n              \n                       [[-1.7280e-01, -1.7847e-01, -2.0613e-02],\n                        [-1.4304e-01, -6.5689e-02, -1.6793e-01],\n                        [ 2.1412e-02,  1.4096e-01, -3.8994e-02]],\n              \n                       [[ 1.2354e-01,  1.9191e-01,  3.8459e-02],\n                        [ 1.4203e-01, -5.6992e-02, -4.6088e-02],\n                        [-1.4754e-01, -2.2810e-02,  9.8464e-02]]],\n              \n              \n                      [[[-1.3586e-01, -1.3718e-01,  8.2752e-02],\n                        [-1.5482e-01,  1.6963e-01,  1.4687e-01],\n                        [-2.7247e-02,  1.7858e-01, -7.3678e-02]],\n              \n                       [[-1.7159e-01, -1.2371e-01, -1.2385e-01],\n                        [-1.2920e-01,  6.2783e-02,  6.6024e-02],\n                        [-1.8779e-01, -1.2211e-01,  3.8094e-02]],\n              \n                       [[-1.1295e-01,  8.2819e-02,  1.6496e-01],\n                        [-3.9714e-03,  1.9033e-01,  4.1283e-02],\n                        [-4.8470e-02,  1.8480e-01, -3.6369e-02]]],\n              \n              \n                      [[[-1.1629e-01, -5.4224e-02, -1.0890e-01],\n                        [-2.7291e-02,  1.0628e-01, -1.3018e-01],\n                        [ 1.4060e-01,  1.4638e-01,  1.6863e-01]],\n              \n                       [[-1.8740e-02, -1.2280e-01, -1.3235e-01],\n                        [-1.1484e-01, -1.1395e-01,  1.0707e-01],\n                        [ 1.3709e-01,  2.7970e-02,  1.6920e-02]],\n              \n                       [[ 1.8639e-01, -5.2864e-02,  9.6797e-02],\n                        [ 7.0529e-02, -2.8378e-02,  4.4390e-02],\n                        [-1.7711e-01,  1.6619e-01, -1.6942e-01]]],\n              \n              \n                      [[[-1.6279e-01, -4.9219e-02,  1.5353e-01],\n                        [-1.8839e-01,  8.2294e-02,  4.8790e-04],\n                        [ 7.5258e-02,  1.8938e-01, -7.4136e-02]],\n              \n                       [[-1.2562e-01,  7.0540e-02, -7.7304e-02],\n                        [ 3.0828e-02,  8.6970e-02, -1.2941e-01],\n                        [-3.1433e-02,  1.2027e-01, -1.4562e-02]],\n              \n                       [[-1.8993e-02, -1.6705e-01, -3.3367e-02],\n                        [-1.4981e-01,  1.0985e-01, -7.8467e-02],\n                        [ 1.6656e-01, -4.0679e-02,  9.9797e-02]]],\n              \n              \n                      [[[-1.8322e-01, -1.4468e-01, -1.3773e-02],\n                        [-3.2226e-02, -8.2798e-02,  1.8543e-01],\n                        [ 1.4629e-01,  2.7941e-02, -3.3442e-02]],\n              \n                       [[-2.1682e-02,  4.7198e-02,  1.7245e-01],\n                        [ 3.1438e-02, -8.3009e-02, -4.1333e-02],\n                        [-1.8165e-02, -4.0764e-02, -1.4947e-01]],\n              \n                       [[-7.2444e-02,  5.6426e-03,  3.1287e-02],\n                        [-1.7199e-01, -8.1849e-03, -1.6719e-01],\n                        [-3.8849e-02, -4.9323e-02, -6.8096e-02]]],\n              \n              \n                      [[[-1.3890e-01,  1.0525e-01,  8.3924e-02],\n                        [ 4.4773e-02,  2.2119e-02, -1.6418e-01],\n                        [ 1.2352e-01,  9.6761e-02,  1.7244e-01]],\n              \n                       [[-2.5276e-02, -1.0806e-01, -1.3081e-01],\n                        [-4.4503e-02, -7.7648e-02,  5.6690e-03],\n                        [-1.1458e-01, -8.9442e-02, -1.6751e-01]],\n              \n                       [[-1.2213e-01, -1.2527e-01,  2.2401e-02],\n                        [-1.5382e-01,  3.3333e-02, -7.8309e-02],\n                        [-5.6995e-02,  3.1346e-02, -2.3310e-03]]],\n              \n              \n                      [[[-6.5960e-02,  1.2505e-01, -1.3980e-01],\n                        [ 1.3501e-01,  1.4793e-01, -1.0307e-01],\n                        [-1.3721e-01, -1.7897e-01,  5.2124e-02]],\n              \n                       [[-1.6238e-01, -6.6839e-02, -4.9294e-03],\n                        [ 4.9535e-02,  9.9993e-02, -9.8577e-02],\n                        [ 1.4358e-01, -1.3360e-01, -6.4534e-02]],\n              \n                       [[-3.6089e-03,  6.3406e-02, -1.0614e-01],\n                        [ 8.0535e-02,  2.8384e-02,  1.4123e-01],\n                        [-6.9385e-02,  1.2876e-01, -4.4518e-03]]],\n              \n              \n                      [[[ 1.3008e-01, -1.6694e-01,  5.4578e-02],\n                        [ 8.4818e-02,  3.2026e-02, -1.6268e-01],\n                        [-1.4047e-04, -1.9067e-01,  8.0252e-02]],\n              \n                       [[-7.0400e-02, -7.4529e-03,  3.6563e-02],\n                        [ 1.4365e-01, -8.7834e-02,  7.6105e-02],\n                        [ 1.7479e-01, -5.8076e-02, -6.7708e-02]],\n              \n                       [[ 3.5240e-02,  4.0548e-02, -1.9204e-01],\n                        [-5.9973e-02,  9.4875e-02, -2.0606e-02],\n                        [-1.0380e-01,  5.0712e-02,  1.2058e-01]]],\n              \n              \n                      [[[ 1.6674e-01, -3.9021e-02,  1.6786e-01],\n                        [-5.2304e-02,  1.5969e-01,  3.5311e-02],\n                        [ 1.6836e-01,  1.2687e-01,  1.7858e-01]],\n              \n                       [[ 7.9284e-02,  1.6319e-01, -3.8867e-02],\n                        [ 1.2428e-01, -1.4613e-01, -6.2890e-02],\n                        [-6.9785e-02,  7.4117e-02, -1.0751e-01]],\n              \n                       [[-9.5267e-02,  2.2557e-02, -1.4064e-01],\n                        [ 7.7146e-02, -9.8587e-02, -6.9290e-02],\n                        [ 2.8576e-02,  9.2575e-02, -8.2016e-02]]],\n              \n              \n                      [[[ 4.4359e-02,  7.5300e-02,  4.5977e-02],\n                        [ 5.9916e-02, -1.7735e-01,  1.7236e-01],\n                        [-1.3908e-01,  6.7665e-02,  1.4182e-01]],\n              \n                       [[-1.7685e-01,  4.6196e-04, -7.6982e-02],\n                        [-1.1118e-01, -7.2353e-02, -1.2598e-01],\n                        [ 9.7591e-02, -2.7843e-02,  6.1334e-02]],\n              \n                       [[-1.0315e-02,  7.1126e-02, -8.1723e-02],\n                        [-1.5678e-01, -1.1023e-01, -1.5237e-01],\n                        [ 6.1180e-02, -1.4583e-02,  7.9908e-02]]],\n              \n              \n                      [[[-1.0304e-01, -1.4235e-01,  1.5422e-01],\n                        [-1.0829e-01,  3.8236e-02,  1.1951e-01],\n                        [ 9.9883e-02, -1.3938e-01,  5.2906e-02]],\n              \n                       [[ 1.3599e-01,  8.9359e-02,  1.6209e-01],\n                        [-7.2530e-02,  1.0400e-01,  1.3314e-02],\n                        [-8.2051e-02,  3.2611e-03, -1.4952e-01]],\n              \n                       [[-1.4335e-01,  1.1364e-01, -2.8912e-02],\n                        [-8.2289e-02,  1.1929e-01, -2.4543e-03],\n                        [-1.4098e-01, -1.5703e-01, -5.2571e-02]]],\n              \n              \n                      [[[-6.8949e-02, -6.2857e-02,  1.2943e-01],\n                        [-6.0073e-02,  2.9595e-02,  2.7560e-02],\n                        [-9.7501e-02,  1.5759e-01,  3.8661e-02]],\n              \n                       [[ 1.1202e-01,  1.6263e-01,  1.4253e-01],\n                        [-1.1172e-01, -7.8918e-02,  1.9106e-01],\n                        [-1.1198e-01, -1.9117e-01, -1.6843e-01]],\n              \n                       [[ 4.7319e-02,  6.7148e-02,  1.3503e-01],\n                        [-6.1792e-02, -1.4935e-01,  8.1161e-02],\n                        [ 3.4864e-02,  7.1342e-02, -6.2181e-02]]],\n              \n              \n                      [[[-4.8329e-02,  1.1173e-01,  1.2843e-01],\n                        [-1.2108e-01,  1.4105e-01,  9.8382e-02],\n                        [-1.9011e-01,  1.1609e-01, -9.5914e-02]],\n              \n                       [[ 1.2962e-01,  1.4630e-01, -7.6154e-02],\n                        [ 8.1274e-02,  1.9029e-01, -1.7605e-02],\n                        [ 1.2943e-01,  1.0775e-01, -1.4916e-01]],\n              \n                       [[-9.2092e-02, -8.6505e-02, -6.6006e-02],\n                        [-9.4957e-02, -1.1378e-01,  5.4206e-02],\n                        [ 3.7026e-02, -1.1841e-02, -3.6577e-02]]],\n              \n              \n                      [[[ 9.4912e-02,  1.2755e-01,  3.9105e-02],\n                        [-1.5663e-01, -1.3693e-01,  1.4858e-01],\n                        [ 1.5233e-01, -1.2802e-01, -1.7879e-01]],\n              \n                       [[ 1.0941e-01, -1.1288e-01, -5.7134e-02],\n                        [ 1.8968e-01,  1.0437e-01, -1.4941e-01],\n                        [-1.3320e-02, -9.4781e-02,  1.9166e-02]],\n              \n                       [[-4.2074e-02, -7.2477e-02,  1.1115e-01],\n                        [-1.0971e-01, -3.2784e-02,  1.3368e-01],\n                        [ 5.8045e-02,  9.0946e-02,  1.0818e-02]]],\n              \n              \n                      [[[-6.6328e-02,  6.7951e-02,  1.0644e-01],\n                        [-9.1804e-02,  6.1881e-02,  1.7166e-02],\n                        [-1.4364e-01, -1.0248e-01,  5.0555e-02]],\n              \n                       [[-5.4000e-02, -4.4460e-02, -1.6571e-01],\n                        [-4.8296e-02, -1.2856e-01,  1.7029e-01],\n                        [-1.0279e-01, -8.2148e-02,  9.1409e-02]],\n              \n                       [[ 1.3770e-01,  4.7044e-02,  1.6435e-02],\n                        [ 2.4718e-02, -2.0467e-02, -1.6461e-01],\n                        [ 1.5315e-01, -1.2575e-01, -7.7645e-02]]],\n              \n              \n                      [[[-1.1852e-01,  1.9576e-02,  1.8631e-01],\n                        [ 1.2837e-01,  5.7395e-02, -2.7520e-02],\n                        [-1.4967e-01,  1.4000e-01, -9.4849e-02]],\n              \n                       [[-1.7230e-01, -1.0975e-01, -1.7614e-01],\n                        [-9.9389e-02, -7.8679e-02,  1.1904e-01],\n                        [-3.6239e-02,  1.0784e-01,  1.5186e-03]],\n              \n                       [[ 1.3171e-01,  1.5942e-01,  1.5151e-01],\n                        [ 1.3922e-01, -1.2441e-01, -1.0083e-01],\n                        [ 7.3286e-02,  1.1240e-01, -7.4830e-03]]],\n              \n              \n                      [[[-1.2881e-01,  5.8815e-02,  1.2111e-01],\n                        [ 3.0346e-02, -3.5824e-02, -3.3483e-02],\n                        [ 4.1113e-02, -1.5744e-01, -1.2451e-01]],\n              \n                       [[ 1.2556e-01,  2.3343e-02, -1.3698e-01],\n                        [ 9.7573e-02,  4.0963e-02,  1.7469e-01],\n                        [ 1.4436e-01, -1.9198e-01, -7.5276e-02]],\n              \n                       [[-1.3408e-01, -6.3639e-02, -7.7709e-02],\n                        [ 4.7408e-02,  1.4112e-01,  1.0904e-01],\n                        [ 1.0149e-01, -4.8047e-02, -1.0996e-01]]],\n              \n              \n                      [[[ 1.4741e-01, -2.8240e-02,  7.0895e-02],\n                        [-5.6996e-02, -1.6042e-01,  4.1013e-02],\n                        [ 1.3369e-01, -1.9846e-02,  1.1370e-01]],\n              \n                       [[-1.2930e-01, -1.2868e-01,  1.5822e-01],\n                        [-1.7795e-01,  1.3668e-01, -9.0079e-02],\n                        [-1.8623e-01, -1.6207e-01,  1.5892e-01]],\n              \n                       [[-9.4111e-02,  1.4633e-02,  1.3853e-02],\n                        [ 1.9216e-01, -1.0224e-01,  4.5357e-02],\n                        [-4.9003e-02,  5.3313e-02, -2.3581e-02]]],\n              \n              \n                      [[[-7.8672e-02,  7.5138e-02, -1.1956e-01],\n                        [-1.1809e-01, -1.0938e-01, -7.2442e-03],\n                        [ 5.4742e-02, -1.3346e-01, -3.0293e-02]],\n              \n                       [[ 9.9387e-02,  1.3820e-01, -7.3040e-02],\n                        [-6.5125e-02, -1.6389e-01, -1.6853e-01],\n                        [-8.0272e-02,  1.1985e-01, -6.0488e-02]],\n              \n                       [[ 2.0315e-03, -1.1569e-01,  1.5564e-01],\n                        [-8.1119e-02,  2.0201e-02,  1.2749e-01],\n                        [ 9.9176e-02,  9.4309e-02,  5.2975e-02]]],\n              \n              \n                      [[[ 9.2569e-02, -6.6237e-03,  8.4486e-02],\n                        [-1.1715e-01, -5.6335e-02, -1.5302e-02],\n                        [ 1.6802e-01, -1.4412e-01, -5.0312e-03]],\n              \n                       [[ 3.1208e-02, -1.6673e-01,  9.2744e-02],\n                        [-1.9114e-01, -2.6277e-02, -1.7786e-01],\n                        [-1.8239e-02,  2.5972e-02,  7.9454e-02]],\n              \n                       [[-1.2514e-01, -5.2405e-02, -9.3916e-02],\n                        [ 1.0005e-01,  1.4393e-01,  1.7370e-01],\n                        [ 8.3283e-02,  4.2337e-02, -5.1839e-02]]],\n              \n              \n                      [[[ 4.9469e-02, -1.4977e-02,  6.6788e-02],\n                        [ 3.6506e-02, -2.1573e-03, -9.2607e-02],\n                        [ 5.1616e-02,  5.4698e-02,  1.6878e-01]],\n              \n                       [[ 1.8411e-01, -3.3292e-02, -1.0669e-02],\n                        [-1.6488e-01, -1.5586e-01,  1.9221e-01],\n                        [-2.1229e-02, -1.7472e-01, -9.8268e-02]],\n              \n                       [[-1.4716e-01, -4.2733e-02, -1.2589e-01],\n                        [ 1.7781e-01,  1.7525e-01, -1.6147e-01],\n                        [-1.3226e-01,  2.1489e-02,  1.3787e-02]]],\n              \n              \n                      [[[ 1.4948e-01,  4.2559e-02, -5.4952e-02],\n                        [ 5.5872e-02,  1.8605e-01,  8.5920e-02],\n                        [ 4.3590e-02, -1.2467e-01,  1.2038e-01]],\n              \n                       [[-1.2159e-01,  1.4193e-01,  1.8605e-02],\n                        [-4.0549e-02,  1.7863e-01, -1.9342e-02],\n                        [ 5.5286e-02, -6.9115e-02, -6.9078e-02]],\n              \n                       [[-3.5690e-03, -1.6938e-01, -1.3217e-01],\n                        [-1.1340e-02,  4.4076e-02, -1.4049e-01],\n                        [ 7.6247e-02, -2.2804e-02,  1.2048e-01]]]])),\n             ('conv1.0.bias',\n              tensor([-1.7672e-01,  2.3573e-02, -1.5684e-01, -1.0635e-01, -4.6007e-02,\n                       4.6424e-02, -1.0463e-03, -7.6291e-02,  1.8539e-01,  9.2516e-02,\n                      -4.9417e-02, -1.1062e-01,  1.5530e-01,  3.1077e-02,  1.6023e-01,\n                      -1.5848e-01,  1.1062e-01,  1.1542e-01, -1.8153e-01,  1.2072e-01,\n                       1.1569e-01,  8.0098e-02,  1.1674e-01,  6.8374e-02,  1.3063e-01,\n                      -3.6455e-05, -1.5143e-01, -1.2896e-01, -1.5063e-01, -5.1814e-02,\n                      -3.9033e-02,  1.1831e-01])),\n             ('conv1.2.weight',\n              tensor([[[[ 2.6148e-02, -2.7530e-02,  1.7448e-02],\n                        [-5.2395e-02,  5.6173e-02, -1.4501e-03],\n                        [ 1.4111e-03,  3.7926e-02, -2.7406e-02]],\n              \n                       [[ 5.8819e-02,  3.9441e-02, -2.8196e-02],\n                        [ 1.2444e-03,  5.3361e-02,  2.8651e-02],\n                        [-3.0148e-02,  2.6137e-02,  2.2611e-02]],\n              \n                       [[ 2.6932e-02,  5.2734e-02,  6.5780e-03],\n                        [-4.6104e-02,  4.0731e-02, -4.2016e-02],\n                        [ 8.9057e-03,  5.8581e-02, -4.5761e-02]],\n              \n                       ...,\n              \n                       [[ 3.1861e-02, -1.4490e-02,  5.6068e-02],\n                        [ 4.5827e-02,  3.4470e-02, -5.5907e-02],\n                        [-5.0506e-02, -5.4546e-02,  1.1357e-03]],\n              \n                       [[-2.4268e-02, -3.2920e-02, -4.2853e-02],\n                        [-5.2432e-02,  1.0192e-02, -2.2739e-02],\n                        [-3.2611e-02, -2.9472e-02,  2.5843e-02]],\n              \n                       [[-3.3063e-02, -5.1748e-02, -5.0873e-02],\n                        [ 5.6541e-02,  2.4765e-02,  1.3724e-02],\n                        [-4.7929e-02, -1.3592e-02,  4.2032e-02]]],\n              \n              \n                      [[[-7.0761e-03, -4.7310e-02,  1.2558e-02],\n                        [ 3.7623e-02, -1.3775e-02,  3.6943e-02],\n                        [ 4.1403e-02, -2.1720e-02, -8.4619e-03]],\n              \n                       [[-1.1620e-03,  5.5789e-02, -1.6098e-02],\n                        [ 3.7725e-02,  2.2119e-02, -1.0595e-02],\n                        [-2.5001e-02, -5.1551e-02, -2.5868e-02]],\n              \n                       [[-2.8940e-02, -2.3542e-02, -3.8925e-02],\n                        [ 4.0942e-02,  5.2361e-02,  4.9799e-02],\n                        [-1.8364e-02, -3.8216e-02, -1.9383e-02]],\n              \n                       ...,\n              \n                       [[-4.3353e-02, -1.7458e-02, -8.3306e-03],\n                        [ 3.8181e-02, -2.4310e-02, -2.8177e-02],\n                        [ 2.6256e-02,  3.5568e-02, -1.0305e-02]],\n              \n                       [[ 3.1680e-02, -3.4473e-04,  4.1480e-05],\n                        [ 5.1462e-02, -3.5737e-03, -2.0465e-02],\n                        [ 5.5397e-02, -2.4668e-02, -3.6191e-03]],\n              \n                       [[-3.0782e-02,  5.4874e-02, -2.1080e-02],\n                        [ 2.0251e-02,  3.8511e-02,  4.6053e-02],\n                        [-1.3044e-02, -3.5470e-02,  5.1296e-02]]],\n              \n              \n                      [[[-4.1796e-02, -5.2930e-02, -2.9476e-02],\n                        [-2.1652e-02,  2.0023e-02,  5.0939e-02],\n                        [-2.1222e-02,  3.1177e-03, -1.2623e-02]],\n              \n                       [[ 2.9312e-02,  2.8206e-02, -8.3885e-03],\n                        [ 4.7271e-02,  4.6322e-02,  2.5685e-02],\n                        [-3.1848e-02,  4.9099e-03, -5.7058e-02]],\n              \n                       [[-4.3859e-02, -5.6913e-02, -2.8963e-02],\n                        [ 3.7518e-02, -1.8092e-02,  3.5068e-02],\n                        [-1.9027e-02,  1.2949e-02, -2.5129e-02]],\n              \n                       ...,\n              \n                       [[ 4.1165e-02, -1.3263e-02,  4.0083e-02],\n                        [-3.3678e-02,  5.6065e-03,  3.0210e-02],\n                        [ 3.9725e-03,  6.9461e-03, -9.2425e-03]],\n              \n                       [[-3.8599e-02,  4.3449e-02, -9.6095e-05],\n                        [-2.4993e-02, -4.4584e-02,  1.6295e-02],\n                        [ 2.4289e-02, -8.1191e-03,  3.8195e-02]],\n              \n                       [[-1.5163e-02,  3.2036e-02,  5.6869e-02],\n                        [ 1.9713e-02,  2.7467e-02, -3.4589e-02],\n                        [-2.6302e-02,  4.4633e-03,  2.0357e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 4.0442e-03,  5.2912e-02,  4.4494e-02],\n                        [-2.7896e-02, -2.3147e-02,  4.8995e-02],\n                        [ 1.0509e-02,  1.5825e-02,  3.0172e-02]],\n              \n                       [[-1.5421e-02, -5.2353e-02,  4.3202e-02],\n                        [ 2.4916e-03, -5.2648e-02,  4.4698e-02],\n                        [-4.6141e-02,  1.8197e-02,  4.8373e-02]],\n              \n                       [[ 3.8286e-02, -1.0908e-02, -4.0337e-02],\n                        [ 2.1738e-02,  6.6272e-03,  2.2000e-02],\n                        [-1.2535e-02, -3.4758e-02, -4.9345e-02]],\n              \n                       ...,\n              \n                       [[-5.0120e-02, -3.2528e-02, -5.5592e-02],\n                        [-1.1200e-02,  7.9766e-03,  8.7075e-03],\n                        [ 2.3584e-02,  3.0025e-02,  5.5278e-02]],\n              \n                       [[-5.0436e-03, -3.1995e-02,  5.1978e-02],\n                        [ 2.9276e-03,  5.3518e-02, -2.0882e-02],\n                        [ 3.0679e-02, -1.6618e-02,  3.7851e-02]],\n              \n                       [[-3.6303e-02,  3.4220e-02,  4.4802e-02],\n                        [-8.3558e-03,  5.1473e-04,  4.1910e-02],\n                        [ 4.8468e-02,  1.9399e-02, -4.5409e-02]]],\n              \n              \n                      [[[-3.0179e-02, -7.2963e-03,  5.1052e-02],\n                        [-2.3719e-02,  5.8051e-02, -3.5339e-02],\n                        [ 3.3614e-02, -4.2115e-02,  4.0632e-02]],\n              \n                       [[-3.2456e-02, -4.5513e-02, -4.5246e-03],\n                        [-4.0734e-02,  2.0896e-03,  2.7514e-02],\n                        [ 1.5728e-02,  1.8183e-02, -5.5186e-02]],\n              \n                       [[ 1.0949e-03,  1.9230e-02, -4.9945e-02],\n                        [-4.1269e-02,  6.6805e-03, -4.6871e-02],\n                        [-4.0286e-02,  3.8403e-02,  1.5744e-03]],\n              \n                       ...,\n              \n                       [[ 3.0748e-02, -3.6423e-02, -3.1035e-02],\n                        [-4.6654e-02, -1.7730e-02, -3.5397e-02],\n                        [-5.3244e-02, -4.5560e-02,  5.7810e-02]],\n              \n                       [[ 2.0425e-02, -5.4063e-02, -5.1005e-02],\n                        [-3.7762e-02,  1.4803e-02,  3.4022e-02],\n                        [ 3.8625e-02, -3.1178e-02,  5.0223e-02]],\n              \n                       [[ 9.3291e-03, -1.4540e-02,  5.4164e-02],\n                        [ 4.5434e-02, -4.9786e-02, -4.9251e-02],\n                        [-3.2379e-02, -2.8824e-03,  1.3601e-02]]],\n              \n              \n                      [[[-5.1858e-02, -2.1766e-03,  2.7883e-02],\n                        [ 1.8398e-03,  3.1548e-02,  1.6752e-02],\n                        [ 2.9093e-02, -2.4359e-02,  1.6610e-02]],\n              \n                       [[ 3.1543e-02, -1.6731e-02,  5.2629e-02],\n                        [ 4.2379e-02,  3.5140e-02,  2.9010e-02],\n                        [ 5.3496e-02,  3.0460e-02, -5.7209e-02]],\n              \n                       [[ 5.3894e-02,  1.9889e-02,  4.7667e-03],\n                        [-3.1577e-03, -2.8389e-02,  5.5141e-02],\n                        [-4.9375e-02, -4.4308e-02,  2.4371e-02]],\n              \n                       ...,\n              \n                       [[ 3.6118e-02, -2.3686e-02,  5.1966e-02],\n                        [ 3.2869e-02,  1.7059e-02,  1.0639e-03],\n                        [-5.0702e-02, -2.7564e-02,  2.1314e-02]],\n              \n                       [[ 3.0032e-02, -1.5357e-02, -4.9743e-02],\n                        [-3.4239e-02, -1.5337e-02,  7.3786e-04],\n                        [-2.9103e-02, -1.0611e-02,  1.0276e-02]],\n              \n                       [[-5.2505e-02,  5.1877e-03,  2.0767e-02],\n                        [-9.7885e-03, -5.1319e-02, -2.1546e-02],\n                        [-3.3945e-03,  3.0880e-02,  4.1896e-02]]]])),\n             ('conv1.2.bias',\n              tensor([ 0.0394, -0.0367, -0.0511, -0.0185, -0.0251, -0.0404,  0.0572,  0.0448,\n                       0.0370,  0.0181,  0.0365, -0.0464, -0.0215,  0.0100,  0.0340,  0.0167,\n                       0.0354,  0.0076,  0.0301, -0.0252, -0.0211, -0.0577, -0.0581,  0.0242,\n                       0.0521,  0.0487,  0.0406,  0.0512,  0.0161,  0.0231, -0.0198, -0.0375])),\n             ('conv2.0.weight',\n              tensor([[[[-0.0273, -0.0312,  0.0517],\n                        [ 0.0449, -0.0382,  0.0528],\n                        [ 0.0298,  0.0499, -0.0347]],\n              \n                       [[-0.0526,  0.0085, -0.0191],\n                        [-0.0293,  0.0190,  0.0417],\n                        [ 0.0030,  0.0407,  0.0004]],\n              \n                       [[-0.0111, -0.0441, -0.0421],\n                        [-0.0544,  0.0482, -0.0405],\n                        [-0.0061,  0.0198,  0.0367]],\n              \n                       ...,\n              \n                       [[-0.0193, -0.0310,  0.0543],\n                        [-0.0010,  0.0358,  0.0296],\n                        [-0.0098, -0.0427, -0.0111]],\n              \n                       [[ 0.0338, -0.0567, -0.0382],\n                        [-0.0364,  0.0275, -0.0204],\n                        [ 0.0088, -0.0286, -0.0518]],\n              \n                       [[-0.0571,  0.0559, -0.0355],\n                        [-0.0056,  0.0356, -0.0473],\n                        [-0.0303, -0.0570, -0.0323]]],\n              \n              \n                      [[[-0.0111,  0.0273, -0.0051],\n                        [ 0.0555, -0.0178,  0.0028],\n                        [ 0.0217, -0.0186, -0.0295]],\n              \n                       [[-0.0372, -0.0546,  0.0368],\n                        [-0.0238,  0.0010, -0.0231],\n                        [ 0.0468,  0.0475,  0.0449]],\n              \n                       [[ 0.0514,  0.0588, -0.0429],\n                        [-0.0104, -0.0341, -0.0457],\n                        [-0.0458, -0.0123,  0.0172]],\n              \n                       ...,\n              \n                       [[-0.0158, -0.0445,  0.0422],\n                        [-0.0104,  0.0285, -0.0314],\n                        [ 0.0198,  0.0566,  0.0514]],\n              \n                       [[-0.0514,  0.0342, -0.0493],\n                        [ 0.0370,  0.0043, -0.0248],\n                        [-0.0335, -0.0031,  0.0135]],\n              \n                       [[ 0.0226, -0.0249,  0.0406],\n                        [ 0.0524,  0.0588, -0.0447],\n                        [ 0.0198,  0.0061, -0.0518]]],\n              \n              \n                      [[[-0.0125, -0.0474, -0.0486],\n                        [-0.0091, -0.0495, -0.0279],\n                        [ 0.0277, -0.0260, -0.0515]],\n              \n                       [[ 0.0294,  0.0435, -0.0045],\n                        [-0.0109,  0.0458, -0.0191],\n                        [ 0.0181, -0.0167, -0.0459]],\n              \n                       [[-0.0322,  0.0346, -0.0176],\n                        [ 0.0254, -0.0440, -0.0408],\n                        [ 0.0576,  0.0263, -0.0497]],\n              \n                       ...,\n              \n                       [[ 0.0239, -0.0547, -0.0422],\n                        [ 0.0155, -0.0016, -0.0227],\n                        [-0.0141,  0.0211,  0.0269]],\n              \n                       [[ 0.0202,  0.0418, -0.0003],\n                        [-0.0581,  0.0119, -0.0083],\n                        [-0.0564,  0.0325,  0.0261]],\n              \n                       [[ 0.0033,  0.0051, -0.0441],\n                        [-0.0527, -0.0493,  0.0281],\n                        [-0.0369, -0.0053, -0.0299]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0584,  0.0284,  0.0130],\n                        [ 0.0170, -0.0148, -0.0232],\n                        [ 0.0272, -0.0377,  0.0551]],\n              \n                       [[ 0.0341,  0.0040,  0.0056],\n                        [-0.0166, -0.0141, -0.0578],\n                        [-0.0269,  0.0379,  0.0314]],\n              \n                       [[-0.0068, -0.0504,  0.0100],\n                        [ 0.0521,  0.0369, -0.0086],\n                        [ 0.0058,  0.0466,  0.0179]],\n              \n                       ...,\n              \n                       [[ 0.0385, -0.0305, -0.0201],\n                        [-0.0130, -0.0376, -0.0028],\n                        [-0.0514,  0.0049,  0.0275]],\n              \n                       [[ 0.0388,  0.0180, -0.0137],\n                        [-0.0075, -0.0563,  0.0148],\n                        [-0.0149,  0.0055,  0.0447]],\n              \n                       [[-0.0440, -0.0211,  0.0391],\n                        [-0.0324,  0.0290,  0.0423],\n                        [ 0.0533, -0.0214, -0.0551]]],\n              \n              \n                      [[[ 0.0117, -0.0118,  0.0055],\n                        [-0.0224, -0.0125, -0.0238],\n                        [ 0.0178, -0.0390, -0.0487]],\n              \n                       [[ 0.0341, -0.0114,  0.0248],\n                        [ 0.0042, -0.0203, -0.0151],\n                        [-0.0259,  0.0575,  0.0080]],\n              \n                       [[ 0.0274, -0.0176, -0.0547],\n                        [-0.0519,  0.0307,  0.0434],\n                        [-0.0363,  0.0483,  0.0316]],\n              \n                       ...,\n              \n                       [[ 0.0335, -0.0369,  0.0401],\n                        [-0.0167,  0.0213,  0.0169],\n                        [ 0.0152,  0.0084,  0.0391]],\n              \n                       [[-0.0227,  0.0175, -0.0502],\n                        [-0.0416, -0.0272,  0.0303],\n                        [-0.0151,  0.0076, -0.0284]],\n              \n                       [[ 0.0442, -0.0326, -0.0310],\n                        [-0.0416, -0.0399,  0.0193],\n                        [ 0.0219, -0.0535, -0.0321]]],\n              \n              \n                      [[[-0.0326, -0.0211, -0.0369],\n                        [-0.0103,  0.0233,  0.0033],\n                        [-0.0204, -0.0548,  0.0437]],\n              \n                       [[-0.0149, -0.0068, -0.0421],\n                        [-0.0445, -0.0269, -0.0579],\n                        [ 0.0487,  0.0375, -0.0276]],\n              \n                       [[ 0.0353,  0.0507,  0.0009],\n                        [-0.0380, -0.0366, -0.0354],\n                        [-0.0088, -0.0462, -0.0466]],\n              \n                       ...,\n              \n                       [[-0.0040,  0.0455, -0.0378],\n                        [ 0.0196, -0.0157, -0.0278],\n                        [ 0.0145,  0.0401,  0.0061]],\n              \n                       [[-0.0496,  0.0571,  0.0576],\n                        [ 0.0065,  0.0330,  0.0406],\n                        [-0.0410,  0.0279, -0.0443]],\n              \n                       [[-0.0045, -0.0051, -0.0110],\n                        [-0.0132,  0.0512,  0.0058],\n                        [ 0.0500, -0.0011, -0.0427]]]])),\n             ('conv2.0.bias',\n              tensor([ 0.0424,  0.0353,  0.0575,  0.0401,  0.0015,  0.0586, -0.0281,  0.0361,\n                      -0.0492, -0.0352,  0.0295,  0.0256, -0.0221,  0.0203,  0.0181, -0.0303,\n                      -0.0199,  0.0570,  0.0566, -0.0242, -0.0531,  0.0289, -0.0411, -0.0253,\n                       0.0523, -0.0360, -0.0005, -0.0256, -0.0404, -0.0020, -0.0545, -0.0366])),\n             ('conv2.2.weight',\n              tensor([[[[ 1.7259e-02, -7.5828e-03, -4.4022e-02],\n                        [ 2.1578e-02,  5.3811e-02,  5.8993e-03],\n                        [ 4.3227e-02, -9.4975e-03, -4.0288e-02]],\n              \n                       [[-3.2717e-02, -9.5930e-03,  3.0803e-02],\n                        [ 3.7490e-02, -8.8945e-03,  1.0733e-04],\n                        [ 2.5584e-02,  5.1340e-02, -4.6836e-02]],\n              \n                       [[-2.6037e-02, -4.6641e-02, -3.8640e-02],\n                        [-4.2768e-02, -2.2072e-02,  4.1424e-03],\n                        [-2.0947e-02,  1.0379e-02, -5.7762e-02]],\n              \n                       ...,\n              \n                       [[ 4.1237e-02, -5.0946e-02, -1.3694e-02],\n                        [-1.8861e-02, -3.9616e-02,  5.5693e-02],\n                        [ 2.4190e-02, -4.4879e-03, -2.7880e-02]],\n              \n                       [[ 2.5057e-02, -3.0192e-02, -4.5284e-02],\n                        [ 2.2128e-02,  2.4964e-02, -3.0077e-02],\n                        [-4.2900e-02, -4.0682e-02,  3.3985e-02]],\n              \n                       [[-3.9806e-02,  1.6587e-02,  1.7371e-02],\n                        [-5.7293e-02,  4.8198e-02, -1.3268e-02],\n                        [ 1.1923e-02,  3.9718e-02, -2.9567e-02]]],\n              \n              \n                      [[[ 5.4734e-02, -5.1596e-02,  4.1900e-02],\n                        [ 2.8596e-03, -3.4481e-02, -4.9556e-02],\n                        [-3.6764e-02,  2.3553e-02,  1.7154e-02]],\n              \n                       [[-5.3940e-02,  3.7362e-02, -5.7880e-02],\n                        [ 5.4305e-02,  5.4929e-02, -1.8649e-02],\n                        [-8.2852e-03, -3.2556e-02,  3.2202e-02]],\n              \n                       [[-4.3398e-02,  2.1394e-02,  1.7288e-02],\n                        [-4.8301e-02, -1.6844e-02,  2.5631e-02],\n                        [-5.2773e-02,  4.7307e-02, -1.4404e-02]],\n              \n                       ...,\n              \n                       [[ 2.2609e-03,  2.1759e-02,  1.0583e-02],\n                        [-2.2384e-02,  3.6101e-02,  1.8059e-02],\n                        [-2.2866e-02, -3.6360e-02, -4.4968e-02]],\n              \n                       [[-3.1440e-02,  1.6336e-02, -1.4830e-02],\n                        [-3.2103e-02, -2.5692e-02,  4.1556e-02],\n                        [ 4.8762e-02,  4.2889e-02, -3.5866e-02]],\n              \n                       [[ 2.8110e-02,  4.9641e-02, -1.2594e-02],\n                        [-4.5130e-02,  4.1544e-02,  1.9046e-02],\n                        [ 4.8668e-02,  8.6505e-03,  1.5053e-02]]],\n              \n              \n                      [[[ 5.3690e-02,  1.2336e-02,  2.3175e-03],\n                        [-4.9138e-02, -4.3998e-02,  1.4000e-02],\n                        [-1.8881e-02,  1.4039e-02,  3.1444e-02]],\n              \n                       [[-2.0493e-02,  1.7196e-03,  5.0139e-02],\n                        [-3.7781e-02, -4.9468e-02,  1.5072e-02],\n                        [ 5.3372e-02,  4.1598e-02,  1.4696e-02]],\n              \n                       [[-1.7898e-02,  2.1727e-05, -2.9195e-02],\n                        [ 3.4205e-02,  3.7445e-02,  2.8903e-02],\n                        [-2.1061e-02, -1.8999e-03,  5.5317e-02]],\n              \n                       ...,\n              \n                       [[-4.9922e-03, -6.3632e-03, -4.6930e-02],\n                        [-3.7046e-02, -1.3527e-02,  1.7883e-02],\n                        [-9.8513e-03, -3.6197e-02,  2.0203e-02]],\n              \n                       [[ 5.3316e-02, -1.2944e-02,  2.1459e-02],\n                        [ 4.5733e-02, -2.5378e-02,  1.7982e-02],\n                        [ 2.8285e-02, -3.8162e-02,  3.4766e-02]],\n              \n                       [[ 3.1866e-02, -3.7467e-02, -8.2281e-03],\n                        [ 6.8280e-03,  5.1654e-02,  4.1510e-02],\n                        [-4.5967e-02, -5.0230e-02, -1.1489e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 3.4937e-02,  3.0715e-02, -4.7135e-02],\n                        [ 3.6476e-04,  5.5809e-02,  1.4469e-03],\n                        [-2.2864e-02,  1.1612e-02, -4.5459e-02]],\n              \n                       [[ 4.4741e-02, -1.0422e-02,  5.1643e-02],\n                        [ 3.4973e-02,  1.2601e-02,  2.2807e-02],\n                        [ 3.0669e-02, -3.3736e-02, -3.4832e-02]],\n              \n                       [[-2.5792e-02, -1.0216e-02, -4.4328e-02],\n                        [-2.0882e-02, -1.1720e-02, -5.0775e-03],\n                        [-2.8763e-02,  1.0151e-02,  5.3191e-02]],\n              \n                       ...,\n              \n                       [[ 3.8820e-02,  1.3529e-02,  1.0927e-02],\n                        [ 2.5060e-02,  2.9852e-02, -1.5039e-02],\n                        [-3.1680e-02, -5.8747e-02,  5.1736e-02]],\n              \n                       [[-4.4409e-02,  1.1440e-02,  3.4636e-02],\n                        [ 5.6636e-02,  3.4058e-02, -5.6019e-02],\n                        [-4.1726e-02,  3.7520e-02,  2.3912e-02]],\n              \n                       [[ 5.1137e-02,  2.3397e-02, -4.0779e-02],\n                        [-2.7443e-02, -5.2685e-03,  4.0545e-02],\n                        [ 4.4913e-02, -1.1964e-02,  3.8237e-02]]],\n              \n              \n                      [[[-4.6205e-02,  4.6606e-02,  9.3008e-03],\n                        [-3.2216e-02, -3.2589e-02, -7.6520e-03],\n                        [-4.2232e-02,  1.3177e-02,  5.6610e-02]],\n              \n                       [[ 3.0315e-02, -1.1624e-02,  4.3473e-02],\n                        [ 2.0275e-02,  3.6932e-02,  2.7544e-02],\n                        [-4.9159e-03,  3.1449e-02,  2.7522e-02]],\n              \n                       [[ 1.0523e-02, -8.3285e-03,  6.9901e-03],\n                        [ 2.2960e-02, -2.0757e-02,  4.4732e-02],\n                        [-3.5174e-02,  2.6118e-02, -4.1269e-02]],\n              \n                       ...,\n              \n                       [[ 3.8653e-02, -1.8698e-02, -2.7247e-02],\n                        [-5.6302e-02, -4.4812e-02,  3.6949e-02],\n                        [-4.2557e-02, -4.8313e-02, -4.6515e-02]],\n              \n                       [[-2.9557e-02, -4.2428e-02,  4.9594e-02],\n                        [ 3.5599e-02,  3.6635e-02,  3.6233e-02],\n                        [ 5.2334e-02,  1.5359e-02, -4.6591e-03]],\n              \n                       [[-3.5298e-02, -5.4945e-02, -4.3509e-02],\n                        [ 4.5493e-02, -3.9262e-02,  4.1605e-04],\n                        [ 4.2761e-02, -5.4966e-02, -1.8117e-02]]],\n              \n              \n                      [[[-4.7146e-02,  2.7394e-02, -1.0756e-02],\n                        [ 1.6337e-02, -1.8433e-02,  6.7363e-03],\n                        [ 1.8143e-02, -5.0288e-02, -2.9281e-02]],\n              \n                       [[ 2.8071e-02,  8.9050e-03, -1.5376e-02],\n                        [-5.2861e-03, -2.0274e-03,  1.4650e-02],\n                        [ 1.7479e-02,  1.0901e-02,  5.5337e-02]],\n              \n                       [[-3.1478e-02, -1.4027e-02, -2.3515e-02],\n                        [-3.2706e-02, -6.7122e-03,  4.4595e-02],\n                        [ 5.7147e-02,  4.4848e-02, -2.2445e-02]],\n              \n                       ...,\n              \n                       [[ 2.0486e-02, -1.9842e-02,  1.2621e-02],\n                        [ 4.1775e-02,  3.2830e-02, -3.7165e-02],\n                        [ 2.2630e-02, -5.7588e-03,  2.6860e-02]],\n              \n                       [[-2.7251e-02,  2.1339e-02,  4.9572e-02],\n                        [ 3.6746e-02, -1.5606e-02, -2.8665e-02],\n                        [ 1.5728e-02,  3.9826e-03, -9.1013e-03]],\n              \n                       [[-5.6925e-03, -2.4474e-02,  3.4557e-02],\n                        [-1.9789e-03,  4.9789e-02, -2.5206e-04],\n                        [ 4.0483e-02,  5.7406e-02,  4.4140e-02]]]])),\n             ('conv2.2.bias',\n              tensor([-0.0054, -0.0158,  0.0161, -0.0164, -0.0418,  0.0232, -0.0067,  0.0324,\n                       0.0048,  0.0112, -0.0475, -0.0343, -0.0496, -0.0404, -0.0020,  0.0391,\n                       0.0526, -0.0090,  0.0002, -0.0433,  0.0057, -0.0210, -0.0457, -0.0314,\n                      -0.0037, -0.0520,  0.0106,  0.0389,  0.0237, -0.0168,  0.0019,  0.0234])),\n             ('classifier.1.weight',\n              tensor([[ 0.0995,  0.0928,  0.1517, -0.0598,  0.0257,  0.0819, -0.0518, -0.0934,\n                        0.0629,  0.1302,  0.1200, -0.1367, -0.1472,  0.0600,  0.1448, -0.0494,\n                        0.0673, -0.1365,  0.1441, -0.0054,  0.0527, -0.0154, -0.1686, -0.0932,\n                       -0.0258,  0.1752,  0.0658,  0.0946,  0.1666, -0.0923, -0.0625, -0.1042]])),\n             ('classifier.1.bias', tensor([0.0114]))])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:32:25.827830500Z",
     "start_time": "2024-01-23T14:32:25.807319800Z"
    }
   },
   "id": "6f282f395ffce6e",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32, 32])\n",
      "torch.Size([1, 32, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.0243]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find image dimensions for linear layer\n",
    "model(img.unsqueeze(0).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:35:09.661855900Z",
     "start_time": "2024-01-23T14:35:09.132986800Z"
    }
   },
   "id": "1f7714925bcc04ea",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "def train_epoch(model,data_loader,loss_fn,optimizer,device):\n",
    "    train_loss, train_acc = 0,0\n",
    "    accuracy = Accuracy(task=\"binary\").to(device)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X).squeeze(1)\n",
    "        batch_loss = loss_fn(y_pred, y.float())\n",
    "        train_loss += batch_loss\n",
    "        y_pred = (y_pred > 0.5).long()\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")\n",
    "\n",
    "def test_epoch(model,data_loader,loss,optimizer,device):\n",
    "  test_loss, test_acc = 0, 0\n",
    "  model.eval()\n",
    "  accuracy = Accuracy(task=\"binary\").to(device)\n",
    "  with torch.inference_mode():\n",
    "    for X,y in test_dataloader:\n",
    "      X,y = X.to(device), y.unsqueeze(1).to(device)\n",
    "      test_pred = model(X)\n",
    "      test_loss += loss(test_pred,y.float())\n",
    "      test_pred = (test_pred > 0.5).long()\n",
    "      test_acc +=  accuracy(test_pred, y)\n",
    "    test_loss/=len(data_loader)\n",
    "    test_acc/=len(data_loader)\n",
    "  print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.2f}% \\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:00:56.238780Z",
     "start_time": "2024-01-23T15:00:56.230778800Z"
    }
   },
   "id": "b1adfc67cf9b99bd",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa861c1c8a4f4aeaa0e67c8d87670ed1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.02031 | Train acc: 1.00%\n",
      "\n",
      "Test loss: 0.0004, Test acc: 1.0000% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.00017 | Train acc: 1.00%\n",
      "\n",
      "Test loss: 0.0002, Test acc: 1.0000% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.00009 | Train acc: 1.00%\n",
      "\n",
      "Test loss: 0.0001, Test acc: 1.0000% \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 3\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "    train_epoch(model, train_dataloader, loss, optimizer, device)\n",
    "    test_epoch(model, test_dataloader, loss, optimizer, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:03:20.049882300Z",
     "start_time": "2024-01-23T15:00:57.830860500Z"
    }
   },
   "id": "18cefc9e4863a017",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "img, l = None, None\n",
    "for images, labels in train_dataloader:\n",
    "    img, l = images[0], labels[0]\n",
    "    break\n",
    "\n",
    "for batch, (X,y) in enumerate(train_dataloader):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T14:44:23.083982700Z",
     "start_time": "2024-01-23T14:44:21.701713700Z"
    }
   },
   "id": "1fb9fc8631e28182",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'first_cnn.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:04:51.598627Z",
     "start_time": "2024-01-23T15:04:51.588627400Z"
    }
   },
   "id": "deea04de5a0bbe76",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "VictimCNNModelV0(\n  (conv1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=8192, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VictimCNNModelV0(3, 32, 1)  # Initialize a model with the same architecture\n",
    "model.load_state_dict(torch.load('first_cnn.pth'))\n",
    "model.to(device)  # Don't forget to move the model to the device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:05:37.898790100Z",
     "start_time": "2024-01-23T15:05:37.853790200Z"
    }
   },
   "id": "901970a998af0519",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: tensor([0, 0, 0, 0], device='cuda:0') | Actual labels: tensor([0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Define the transformation\n",
    "transformation = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Load the images from the test folder\n",
    "test_data_dir = \"./test\"  # Replace with your test folder path\n",
    "test_dataset = ImageFolder(root=test_data_dir, transform=transformation)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Load the trained model\n",
    "model = VictimCNNModelV0(3, 32, 1)  # Initialize a model with the same architecture\n",
    "model.load_state_dict(torch.load('first_cnn.pth'))\n",
    "model.to(device)  # Don't forget to move the model to the device\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Predict the labels for the test images\n",
    "for images, l in test_dataloader:\n",
    "    images = images.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(f\"Predicted labels: {predicted} | Actual labels: {l}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:10:08.831857500Z",
     "start_time": "2024-01-23T15:10:08.714343700Z"
    }
   },
   "id": "6cde2151b7af0690",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b0d006f4ee4dba81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "44d0cb165ca1387e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4b828f7ee2350140"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
