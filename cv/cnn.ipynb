{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:03.705274700Z",
     "start_time": "2024-01-23T15:41:03.658273700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:03.733275700Z",
     "start_time": "2024-01-23T15:41:03.708274500Z"
    }
   },
   "id": "e0056f016dbd1df8",
   "execution_count": 166
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 1 - Prepare data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eeab916d55c87e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data is loaded from a video and split into frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b214a1d20ede5f9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, ColorJitter\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the transformations\n",
    "transformation = Compose([\n",
    "    Resize((64, 64)),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomRotation(30),\n",
    "    ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:03.734274700Z",
     "start_time": "2024-01-23T15:41:03.731274Z"
    }
   },
   "id": "890ca8e113a4470f",
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \"./dataset\"\n",
    "dataset = ImageFolder(root=data_dir, transform=transformation)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "img, l = None, None\n",
    "for images, labels in data_loader:\n",
    "    img, l = images[0], labels[0]\n",
    "    break\n",
    "img_test = img.permute(1, 2, 0).numpy()\n",
    "plt.imshow(img_test)\n",
    "plt.title(f\"Label: {l}\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.629311900Z",
     "start_time": "2024-01-23T15:41:03.736272700Z"
    }
   },
   "id": "151530569521fd6d",
   "execution_count": 168
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ef73a014c644bac6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 64])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.629311900Z",
     "start_time": "2024-01-23T15:41:04.622311800Z"
    }
   },
   "id": "d22a13f8b90b0ed9",
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "test_len = 0.3\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.637311400Z",
     "start_time": "2024-01-23T15:41:04.626311900Z"
    }
   },
   "id": "681f023702adb483",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int((1-test_len) * len(dataset))\n",
    "test_size = int(test_len * len(dataset))\n",
    "extra = len(dataset) - (train_size + test_size)\n",
    "train_size = train_size + extra if extra > 0 else train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False) # no need to shuffle test data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.686311200Z",
     "start_time": "2024-01-23T15:41:04.638312Z"
    }
   },
   "id": "9b8b8b6afcd68890",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define NN\n",
    "from torch import nn\n",
    "\n",
    "class VictimCNNModelV0(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_units, output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units*16*16,\n",
    "                out_features=output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.687311600Z",
     "start_time": "2024-01-23T15:41:04.648311900Z"
    }
   },
   "id": "64af8d04e2dc80af",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.687311600Z",
     "start_time": "2024-01-23T15:41:04.655311800Z"
    }
   },
   "id": "4e1f82ff1a54fe04",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = VictimCNNModelV0(3, 32, 1).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.688312400Z",
     "start_time": "2024-01-23T15:41:04.667311600Z"
    }
   },
   "id": "f997ae76db52b39b",
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('conv1.0.weight',\n              tensor([[[[ 0.1084,  0.1443, -0.0462],\n                        [ 0.1162,  0.0145,  0.1804],\n                        [ 0.1662,  0.1887, -0.1346]],\n              \n                       [[-0.0816,  0.0866,  0.0374],\n                        [-0.1236,  0.0914,  0.1622],\n                        [ 0.1213,  0.1064, -0.1116]],\n              \n                       [[ 0.1621, -0.1172,  0.0732],\n                        [-0.0675,  0.0586, -0.0998],\n                        [-0.0384, -0.0556,  0.0127]]],\n              \n              \n                      [[[ 0.1716, -0.0818, -0.0504],\n                        [ 0.0790, -0.0244, -0.1082],\n                        [ 0.1260,  0.1327,  0.1551]],\n              \n                       [[-0.0172, -0.1469, -0.1497],\n                        [-0.0705,  0.0084, -0.1922],\n                        [-0.1481, -0.1820,  0.1608]],\n              \n                       [[-0.1036, -0.1871,  0.0287],\n                        [-0.0526,  0.0856, -0.1462],\n                        [-0.0417,  0.0200,  0.0967]]],\n              \n              \n                      [[[ 0.1525,  0.1901, -0.0523],\n                        [-0.1559, -0.0759, -0.0180],\n                        [ 0.0341, -0.0518, -0.1063]],\n              \n                       [[-0.0107, -0.0412,  0.1768],\n                        [-0.1144, -0.0656, -0.0127],\n                        [ 0.1407,  0.0410, -0.1171]],\n              \n                       [[-0.0625, -0.1715, -0.1294],\n                        [-0.0334,  0.0517, -0.1745],\n                        [ 0.0462, -0.1542,  0.1798]]],\n              \n              \n                      [[[ 0.0466,  0.1804,  0.0425],\n                        [-0.1609, -0.1811,  0.1579],\n                        [-0.0367, -0.1495,  0.1023]],\n              \n                       [[ 0.0325, -0.1333, -0.1140],\n                        [ 0.0826, -0.1760,  0.0580],\n                        [ 0.1633,  0.1871,  0.1669]],\n              \n                       [[-0.0566, -0.1451, -0.0884],\n                        [ 0.0407, -0.1091,  0.0053],\n                        [ 0.0717,  0.0074,  0.0359]]],\n              \n              \n                      [[[-0.1089,  0.0338, -0.0007],\n                        [ 0.1902,  0.1413, -0.1805],\n                        [-0.1180,  0.1911, -0.0918]],\n              \n                       [[ 0.0110,  0.0655,  0.0392],\n                        [-0.0829, -0.1597, -0.0039],\n                        [ 0.1276, -0.1518,  0.0572]],\n              \n                       [[ 0.0387, -0.1763,  0.1174],\n                        [-0.0211,  0.1600,  0.1504],\n                        [ 0.1337, -0.1705, -0.0706]]],\n              \n              \n                      [[[-0.0167, -0.0021,  0.1023],\n                        [-0.1253, -0.1063,  0.1748],\n                        [ 0.0090,  0.1848,  0.1767]],\n              \n                       [[-0.0114, -0.1214, -0.0205],\n                        [-0.0294, -0.0738,  0.0848],\n                        [ 0.1680, -0.1062, -0.0947]],\n              \n                       [[ 0.1116,  0.1417, -0.1404],\n                        [-0.1539, -0.1462, -0.0908],\n                        [-0.0226,  0.0419,  0.1649]]],\n              \n              \n                      [[[ 0.0478, -0.1371,  0.1004],\n                        [ 0.0390,  0.0980,  0.1044],\n                        [-0.0827, -0.0709, -0.0387]],\n              \n                       [[ 0.0215,  0.0863, -0.1898],\n                        [-0.0648,  0.0815,  0.1887],\n                        [ 0.0275,  0.0459,  0.0822]],\n              \n                       [[-0.1647,  0.1480,  0.1689],\n                        [-0.1912,  0.1070, -0.1541],\n                        [ 0.1697,  0.1832, -0.0262]]],\n              \n              \n                      [[[-0.1750, -0.0582, -0.0263],\n                        [ 0.1754,  0.0016,  0.0250],\n                        [ 0.0765, -0.0233, -0.0432]],\n              \n                       [[-0.1456,  0.0934, -0.1150],\n                        [-0.1220,  0.1711, -0.0433],\n                        [ 0.0874,  0.1242, -0.0769]],\n              \n                       [[-0.0242, -0.1228,  0.1050],\n                        [-0.1493,  0.1488,  0.1388],\n                        [ 0.1622, -0.0662,  0.0816]]],\n              \n              \n                      [[[-0.0735,  0.0800, -0.1219],\n                        [-0.0679,  0.0050,  0.0142],\n                        [-0.1149,  0.1129,  0.1110]],\n              \n                       [[-0.1914, -0.1198,  0.1201],\n                        [ 0.1155,  0.1282,  0.1691],\n                        [-0.1129,  0.1025, -0.1212]],\n              \n                       [[-0.0173,  0.0013,  0.0783],\n                        [ 0.1483,  0.1139, -0.1509],\n                        [-0.1303, -0.1033, -0.0789]]],\n              \n              \n                      [[[-0.0531,  0.0881, -0.0987],\n                        [-0.1675,  0.1211,  0.0543],\n                        [ 0.0272,  0.0020, -0.0922]],\n              \n                       [[-0.1695,  0.1891, -0.1326],\n                        [ 0.0590,  0.1091, -0.1633],\n                        [-0.0761, -0.0695, -0.0680]],\n              \n                       [[-0.0756, -0.0642, -0.0707],\n                        [-0.1305,  0.0508, -0.0058],\n                        [-0.0070,  0.1878,  0.1308]]],\n              \n              \n                      [[[-0.0375,  0.0492,  0.0726],\n                        [ 0.0768, -0.0824,  0.0725],\n                        [ 0.1267,  0.1460, -0.1642]],\n              \n                       [[-0.1868,  0.0222,  0.1914],\n                        [ 0.0951, -0.1453,  0.0152],\n                        [-0.1359, -0.0046, -0.0499]],\n              \n                       [[-0.1386, -0.0607, -0.1549],\n                        [ 0.1150,  0.0434, -0.1707],\n                        [ 0.0864,  0.1300, -0.0341]]],\n              \n              \n                      [[[-0.1157,  0.1592, -0.1122],\n                        [-0.0200, -0.0210,  0.1260],\n                        [ 0.1820, -0.0383,  0.0595]],\n              \n                       [[ 0.1871,  0.0190,  0.1460],\n                        [-0.1131, -0.0465, -0.1763],\n                        [ 0.0528, -0.1220,  0.1110]],\n              \n                       [[-0.1827,  0.0787,  0.1064],\n                        [-0.1531,  0.1651,  0.1475],\n                        [-0.0773, -0.0148, -0.1280]]],\n              \n              \n                      [[[-0.0643,  0.0821, -0.1829],\n                        [-0.0069, -0.0837, -0.1563],\n                        [-0.0784, -0.0794, -0.0213]],\n              \n                       [[ 0.0722, -0.1848,  0.0686],\n                        [ 0.0958,  0.1498,  0.1009],\n                        [-0.1797, -0.0159,  0.1070]],\n              \n                       [[-0.0274,  0.0566, -0.1417],\n                        [-0.0529, -0.0147, -0.1040],\n                        [ 0.1752, -0.1365,  0.0791]]],\n              \n              \n                      [[[ 0.1169,  0.0166, -0.1029],\n                        [-0.1215,  0.0762, -0.1376],\n                        [-0.1188, -0.1200,  0.0194]],\n              \n                       [[-0.0950,  0.1896, -0.1033],\n                        [-0.0959,  0.0564, -0.0949],\n                        [ 0.1544,  0.1892, -0.0951]],\n              \n                       [[ 0.1400, -0.1343, -0.0879],\n                        [ 0.0267,  0.0643, -0.1632],\n                        [-0.0540, -0.0462, -0.0034]]],\n              \n              \n                      [[[-0.1642, -0.0361, -0.1873],\n                        [ 0.1216, -0.0836,  0.0281],\n                        [-0.1536, -0.1059,  0.1544]],\n              \n                       [[ 0.0187,  0.0900,  0.0954],\n                        [-0.1172,  0.1400,  0.0347],\n                        [ 0.1662,  0.0480,  0.1305]],\n              \n                       [[ 0.0119,  0.0456, -0.0333],\n                        [ 0.1633, -0.0138,  0.0519],\n                        [ 0.1236,  0.1169, -0.1288]]],\n              \n              \n                      [[[-0.0711, -0.1099,  0.1319],\n                        [-0.0802,  0.0180, -0.1425],\n                        [ 0.0044, -0.1525, -0.1044]],\n              \n                       [[-0.0078, -0.0223,  0.1091],\n                        [-0.1707, -0.1728, -0.1347],\n                        [ 0.1059, -0.0922,  0.1152]],\n              \n                       [[-0.0567, -0.0309, -0.0791],\n                        [ 0.1302, -0.0618, -0.0407],\n                        [ 0.0890,  0.0351, -0.0515]]],\n              \n              \n                      [[[ 0.1464,  0.1920,  0.1013],\n                        [-0.1360, -0.1222,  0.0071],\n                        [-0.1715, -0.1208, -0.0232]],\n              \n                       [[-0.1458,  0.0976, -0.0510],\n                        [ 0.0678, -0.0260, -0.0286],\n                        [-0.0175,  0.1723, -0.0200]],\n              \n                       [[ 0.0025,  0.1264,  0.1488],\n                        [-0.1189,  0.1197,  0.0442],\n                        [-0.1525,  0.0794, -0.1718]]],\n              \n              \n                      [[[-0.1834,  0.1475,  0.0790],\n                        [ 0.1887,  0.1609, -0.0106],\n                        [-0.0953, -0.1405, -0.1629]],\n              \n                       [[-0.0415, -0.0825, -0.1755],\n                        [-0.1725, -0.1002, -0.1239],\n                        [-0.0359,  0.0968, -0.0884]],\n              \n                       [[-0.0734, -0.0962,  0.0551],\n                        [ 0.1267, -0.0081,  0.0945],\n                        [ 0.1312, -0.1210,  0.0842]]],\n              \n              \n                      [[[ 0.0091,  0.0490, -0.0931],\n                        [-0.0496, -0.1280, -0.0430],\n                        [-0.1895,  0.0555,  0.0611]],\n              \n                       [[ 0.1721,  0.0221, -0.1661],\n                        [-0.0767,  0.1166,  0.0526],\n                        [-0.0921, -0.0976,  0.0904]],\n              \n                       [[ 0.0389, -0.1402, -0.0514],\n                        [ 0.1675,  0.0236, -0.0368],\n                        [-0.0222, -0.1324, -0.1611]]],\n              \n              \n                      [[[-0.0838, -0.1324,  0.1655],\n                        [-0.0880,  0.0076, -0.1240],\n                        [ 0.1447, -0.1586, -0.1801]],\n              \n                       [[-0.0490,  0.0121,  0.0827],\n                        [-0.1333, -0.1576, -0.0147],\n                        [-0.1061,  0.1115,  0.1787]],\n              \n                       [[-0.1889, -0.0106,  0.0939],\n                        [-0.1858, -0.1827, -0.0117],\n                        [-0.0596, -0.1094, -0.0015]]],\n              \n              \n                      [[[ 0.0974, -0.0655,  0.0717],\n                        [-0.0388,  0.1917, -0.0546],\n                        [ 0.0337,  0.0242, -0.0160]],\n              \n                       [[-0.0673,  0.1602, -0.1632],\n                        [ 0.1770, -0.1782,  0.1124],\n                        [-0.1647,  0.0885,  0.0756]],\n              \n                       [[ 0.1247,  0.0344, -0.0832],\n                        [ 0.0327,  0.0290, -0.0757],\n                        [-0.1385,  0.1924,  0.1292]]],\n              \n              \n                      [[[-0.1754, -0.0391, -0.0965],\n                        [-0.1133, -0.0149,  0.1922],\n                        [-0.0874,  0.1663,  0.0982]],\n              \n                       [[-0.1160, -0.0129,  0.1087],\n                        [ 0.0718,  0.0683,  0.1104],\n                        [-0.0791, -0.1805,  0.1164]],\n              \n                       [[-0.0987, -0.0253,  0.1443],\n                        [-0.0942,  0.1689,  0.0542],\n                        [ 0.1586,  0.1734, -0.1430]]],\n              \n              \n                      [[[-0.1853, -0.0933,  0.1212],\n                        [-0.0483,  0.1313,  0.1912],\n                        [ 0.1306,  0.0638,  0.0242]],\n              \n                       [[ 0.0306,  0.1264, -0.1578],\n                        [ 0.1574,  0.0835,  0.0996],\n                        [-0.0179,  0.1432,  0.0128]],\n              \n                       [[ 0.1258, -0.0995, -0.0709],\n                        [ 0.0236,  0.1218, -0.1576],\n                        [ 0.0118, -0.0049,  0.0989]]],\n              \n              \n                      [[[ 0.0081,  0.0582,  0.1766],\n                        [-0.1247,  0.1191,  0.1822],\n                        [ 0.1498, -0.0028,  0.0589]],\n              \n                       [[-0.0164,  0.0436,  0.0861],\n                        [ 0.1656, -0.0133, -0.0765],\n                        [ 0.1421, -0.0083, -0.0832]],\n              \n                       [[ 0.1276, -0.0485, -0.0702],\n                        [ 0.1084,  0.1398,  0.1799],\n                        [ 0.1537,  0.0337,  0.1909]]],\n              \n              \n                      [[[ 0.0386, -0.0155, -0.0941],\n                        [-0.1061,  0.1345,  0.0033],\n                        [ 0.1526,  0.0160, -0.0893]],\n              \n                       [[ 0.1668, -0.0942,  0.1518],\n                        [-0.1899, -0.0055,  0.1157],\n                        [ 0.0454,  0.0991, -0.0706]],\n              \n                       [[ 0.0445, -0.0333, -0.0322],\n                        [ 0.1232, -0.1677, -0.1410],\n                        [ 0.1640, -0.0038,  0.1883]]],\n              \n              \n                      [[[ 0.1233, -0.1183,  0.0656],\n                        [ 0.0880,  0.0567,  0.1194],\n                        [ 0.1193,  0.0272, -0.0437]],\n              \n                       [[-0.0598, -0.0098, -0.0789],\n                        [ 0.1894, -0.0569,  0.0956],\n                        [-0.1172,  0.1856, -0.0075]],\n              \n                       [[ 0.1070, -0.1466,  0.1068],\n                        [-0.0718,  0.0288,  0.1238],\n                        [-0.0579,  0.1009, -0.1343]]],\n              \n              \n                      [[[ 0.0601, -0.0592,  0.0672],\n                        [ 0.1703, -0.0305,  0.0629],\n                        [-0.1753, -0.1638,  0.1605]],\n              \n                       [[-0.0831, -0.0198,  0.1116],\n                        [-0.1583, -0.0754, -0.1912],\n                        [ 0.1600,  0.0908,  0.0249]],\n              \n                       [[ 0.1245,  0.0959, -0.1281],\n                        [ 0.1667,  0.1874, -0.0467],\n                        [-0.0347,  0.1799,  0.1033]]],\n              \n              \n                      [[[-0.0884,  0.1393,  0.0459],\n                        [-0.0300, -0.1168,  0.0225],\n                        [-0.1176,  0.1307,  0.1108]],\n              \n                       [[-0.0092, -0.0962,  0.0148],\n                        [-0.1844,  0.0320,  0.0113],\n                        [-0.1101, -0.0173, -0.1731]],\n              \n                       [[ 0.0187, -0.1190,  0.0070],\n                        [ 0.0542, -0.0863, -0.0309],\n                        [-0.0557,  0.0032, -0.0758]]],\n              \n              \n                      [[[-0.1689,  0.1809, -0.0546],\n                        [ 0.0787, -0.1743, -0.0576],\n                        [-0.0593,  0.1306, -0.0010]],\n              \n                       [[-0.0041, -0.0561,  0.0929],\n                        [ 0.0844,  0.0263, -0.0617],\n                        [ 0.1370, -0.0347,  0.0104]],\n              \n                       [[-0.1258, -0.1681,  0.1605],\n                        [ 0.0111,  0.1728,  0.0691],\n                        [ 0.0865,  0.1888,  0.1540]]],\n              \n              \n                      [[[-0.1332,  0.0058, -0.0512],\n                        [ 0.0136, -0.0155,  0.1351],\n                        [ 0.1853, -0.0235,  0.1695]],\n              \n                       [[ 0.0629, -0.0305, -0.0954],\n                        [-0.1120,  0.0911,  0.0342],\n                        [ 0.0435, -0.0354, -0.1821]],\n              \n                       [[ 0.0192,  0.1734, -0.1176],\n                        [ 0.1046,  0.0687, -0.0545],\n                        [-0.1460,  0.0742,  0.0309]]],\n              \n              \n                      [[[ 0.0870,  0.0464, -0.0159],\n                        [-0.0689, -0.0976, -0.0806],\n                        [ 0.1081,  0.1891, -0.0413]],\n              \n                       [[-0.0949,  0.0078, -0.1332],\n                        [-0.1296, -0.0163,  0.1607],\n                        [ 0.0678, -0.1041,  0.1228]],\n              \n                       [[ 0.0137, -0.1324,  0.1565],\n                        [-0.1246,  0.1466, -0.0529],\n                        [ 0.1911, -0.1178,  0.0899]]],\n              \n              \n                      [[[ 0.0862,  0.0458,  0.1827],\n                        [ 0.0960,  0.0991,  0.1565],\n                        [-0.0512, -0.0881,  0.0579]],\n              \n                       [[ 0.0951, -0.0862, -0.1049],\n                        [-0.1480, -0.1415,  0.1133],\n                        [ 0.1858,  0.0081, -0.1627]],\n              \n                       [[ 0.1667, -0.1084, -0.0548],\n                        [ 0.0862, -0.1560,  0.0839],\n                        [-0.0380, -0.0387,  0.0916]]]], device='cuda:0')),\n             ('conv1.0.bias',\n              tensor([-0.0617, -0.1139,  0.1310, -0.0590, -0.0650, -0.0863,  0.1724, -0.0916,\n                       0.1195, -0.1458, -0.1809,  0.1690,  0.0695, -0.0069, -0.0710, -0.1265,\n                       0.0905,  0.1504, -0.1796,  0.0971,  0.0085, -0.0578,  0.0923, -0.0732,\n                       0.0718,  0.0914,  0.0750, -0.0797, -0.0243,  0.1678, -0.0206, -0.1156],\n                     device='cuda:0')),\n             ('conv1.2.weight',\n              tensor([[[[-0.0168,  0.0469, -0.0536],\n                        [ 0.0198, -0.0252, -0.0070],\n                        [-0.0048, -0.0481,  0.0159]],\n              \n                       [[-0.0533,  0.0201, -0.0160],\n                        [ 0.0329,  0.0184, -0.0043],\n                        [-0.0501, -0.0204, -0.0185]],\n              \n                       [[ 0.0278,  0.0077,  0.0309],\n                        [-0.0530, -0.0012,  0.0031],\n                        [-0.0524,  0.0284, -0.0076]],\n              \n                       ...,\n              \n                       [[ 0.0518,  0.0101,  0.0466],\n                        [ 0.0315, -0.0015,  0.0293],\n                        [-0.0083,  0.0397, -0.0533]],\n              \n                       [[-0.0082,  0.0242, -0.0144],\n                        [ 0.0477,  0.0539,  0.0484],\n                        [ 0.0379, -0.0417, -0.0217]],\n              \n                       [[-0.0544,  0.0114,  0.0006],\n                        [-0.0042,  0.0086,  0.0473],\n                        [-0.0171,  0.0135, -0.0265]]],\n              \n              \n                      [[[ 0.0435, -0.0169, -0.0517],\n                        [ 0.0454, -0.0279, -0.0083],\n                        [-0.0392, -0.0035, -0.0028]],\n              \n                       [[ 0.0156, -0.0235,  0.0579],\n                        [ 0.0473, -0.0318,  0.0233],\n                        [-0.0291, -0.0162, -0.0164]],\n              \n                       [[-0.0359,  0.0469,  0.0561],\n                        [-0.0174,  0.0058,  0.0156],\n                        [-0.0415,  0.0422, -0.0239]],\n              \n                       ...,\n              \n                       [[-0.0084, -0.0384,  0.0413],\n                        [-0.0353, -0.0511, -0.0377],\n                        [-0.0027, -0.0405, -0.0303]],\n              \n                       [[-0.0038,  0.0573, -0.0341],\n                        [-0.0081, -0.0447,  0.0128],\n                        [ 0.0093,  0.0006, -0.0100]],\n              \n                       [[ 0.0229,  0.0403,  0.0011],\n                        [-0.0452, -0.0311, -0.0288],\n                        [ 0.0477, -0.0122,  0.0209]]],\n              \n              \n                      [[[ 0.0080,  0.0439,  0.0364],\n                        [ 0.0399,  0.0216, -0.0420],\n                        [-0.0322,  0.0290, -0.0428]],\n              \n                       [[-0.0083,  0.0452,  0.0415],\n                        [ 0.0280, -0.0227, -0.0400],\n                        [-0.0118, -0.0296, -0.0007]],\n              \n                       [[-0.0115, -0.0336,  0.0426],\n                        [ 0.0278, -0.0181,  0.0076],\n                        [-0.0105,  0.0535,  0.0346]],\n              \n                       ...,\n              \n                       [[ 0.0086, -0.0142,  0.0051],\n                        [ 0.0419, -0.0577,  0.0216],\n                        [ 0.0512, -0.0454,  0.0552]],\n              \n                       [[-0.0154,  0.0311,  0.0490],\n                        [ 0.0128,  0.0009,  0.0282],\n                        [-0.0027, -0.0515, -0.0287]],\n              \n                       [[ 0.0137, -0.0571, -0.0469],\n                        [ 0.0153,  0.0334, -0.0470],\n                        [ 0.0519,  0.0163,  0.0478]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0472, -0.0104, -0.0286],\n                        [-0.0016, -0.0576,  0.0223],\n                        [-0.0131, -0.0232, -0.0430]],\n              \n                       [[ 0.0587,  0.0296,  0.0325],\n                        [-0.0305, -0.0172,  0.0512],\n                        [-0.0096, -0.0432,  0.0072]],\n              \n                       [[-0.0136,  0.0384,  0.0088],\n                        [-0.0563, -0.0308,  0.0182],\n                        [ 0.0338, -0.0554, -0.0233]],\n              \n                       ...,\n              \n                       [[-0.0178, -0.0518,  0.0378],\n                        [ 0.0401, -0.0045,  0.0430],\n                        [-0.0183,  0.0515,  0.0164]],\n              \n                       [[-0.0377,  0.0100, -0.0172],\n                        [ 0.0267, -0.0390, -0.0247],\n                        [-0.0305,  0.0431,  0.0426]],\n              \n                       [[-0.0483,  0.0334,  0.0545],\n                        [-0.0376,  0.0262,  0.0568],\n                        [ 0.0075,  0.0333, -0.0051]]],\n              \n              \n                      [[[-0.0293,  0.0153,  0.0568],\n                        [-0.0411,  0.0029,  0.0117],\n                        [-0.0081,  0.0003,  0.0439]],\n              \n                       [[-0.0265, -0.0076,  0.0535],\n                        [ 0.0527,  0.0450, -0.0584],\n                        [ 0.0357, -0.0275,  0.0524]],\n              \n                       [[ 0.0006,  0.0126, -0.0460],\n                        [-0.0362, -0.0369, -0.0412],\n                        [ 0.0256,  0.0184, -0.0314]],\n              \n                       ...,\n              \n                       [[ 0.0551, -0.0203, -0.0089],\n                        [-0.0413, -0.0500,  0.0282],\n                        [ 0.0424, -0.0232, -0.0550]],\n              \n                       [[ 0.0149,  0.0409,  0.0156],\n                        [ 0.0119, -0.0291, -0.0246],\n                        [-0.0066,  0.0032, -0.0386]],\n              \n                       [[-0.0240, -0.0304, -0.0195],\n                        [ 0.0128,  0.0272, -0.0550],\n                        [-0.0475,  0.0238, -0.0021]]],\n              \n              \n                      [[[ 0.0010, -0.0440,  0.0571],\n                        [ 0.0195, -0.0290,  0.0314],\n                        [-0.0167, -0.0374, -0.0585]],\n              \n                       [[-0.0086, -0.0521, -0.0526],\n                        [ 0.0403, -0.0023,  0.0359],\n                        [-0.0113, -0.0570,  0.0210]],\n              \n                       [[ 0.0437, -0.0008,  0.0204],\n                        [-0.0299, -0.0244,  0.0366],\n                        [ 0.0576, -0.0279,  0.0582]],\n              \n                       ...,\n              \n                       [[-0.0447, -0.0035,  0.0373],\n                        [-0.0042,  0.0079,  0.0216],\n                        [-0.0136,  0.0120, -0.0315]],\n              \n                       [[ 0.0193, -0.0543, -0.0551],\n                        [ 0.0496, -0.0329, -0.0293],\n                        [ 0.0020, -0.0101,  0.0126]],\n              \n                       [[ 0.0554, -0.0321, -0.0263],\n                        [-0.0510, -0.0532,  0.0455],\n                        [-0.0385,  0.0158,  0.0315]]]], device='cuda:0')),\n             ('conv1.2.bias',\n              tensor([-0.0260,  0.0242, -0.0531,  0.0287, -0.0193,  0.0334,  0.0313,  0.0570,\n                       0.0406, -0.0274,  0.0500, -0.0141, -0.0533,  0.0279,  0.0530, -0.0024,\n                       0.0442,  0.0136, -0.0458, -0.0185, -0.0309, -0.0583,  0.0385,  0.0101,\n                       0.0233, -0.0331, -0.0317, -0.0264, -0.0178,  0.0221, -0.0143,  0.0464],\n                     device='cuda:0')),\n             ('conv2.0.weight',\n              tensor([[[[-0.0211,  0.0077, -0.0210],\n                        [-0.0095, -0.0552,  0.0292],\n                        [-0.0121, -0.0477,  0.0322]],\n              \n                       [[ 0.0170,  0.0205, -0.0413],\n                        [ 0.0166, -0.0328,  0.0401],\n                        [ 0.0023,  0.0304,  0.0368]],\n              \n                       [[-0.0028,  0.0051, -0.0129],\n                        [ 0.0436,  0.0268,  0.0367],\n                        [ 0.0520,  0.0274,  0.0014]],\n              \n                       ...,\n              \n                       [[-0.0105,  0.0021,  0.0091],\n                        [ 0.0143, -0.0175, -0.0225],\n                        [-0.0071, -0.0085, -0.0153]],\n              \n                       [[ 0.0453, -0.0461,  0.0111],\n                        [ 0.0232,  0.0578,  0.0406],\n                        [ 0.0463, -0.0270, -0.0519]],\n              \n                       [[ 0.0336,  0.0327,  0.0379],\n                        [ 0.0428, -0.0018,  0.0389],\n                        [ 0.0154,  0.0090, -0.0532]]],\n              \n              \n                      [[[-0.0468, -0.0161, -0.0432],\n                        [-0.0034,  0.0499,  0.0537],\n                        [-0.0007,  0.0040,  0.0464]],\n              \n                       [[-0.0572, -0.0073, -0.0579],\n                        [ 0.0545,  0.0264,  0.0278],\n                        [ 0.0151, -0.0542,  0.0156]],\n              \n                       [[-0.0246,  0.0539, -0.0292],\n                        [ 0.0047, -0.0174, -0.0185],\n                        [-0.0385,  0.0155,  0.0180]],\n              \n                       ...,\n              \n                       [[-0.0475, -0.0239,  0.0332],\n                        [ 0.0392,  0.0062,  0.0466],\n                        [-0.0489, -0.0127,  0.0526]],\n              \n                       [[ 0.0092,  0.0160, -0.0510],\n                        [-0.0084,  0.0030, -0.0140],\n                        [-0.0032,  0.0105, -0.0164]],\n              \n                       [[-0.0173, -0.0351, -0.0154],\n                        [ 0.0199,  0.0083,  0.0419],\n                        [-0.0453, -0.0201, -0.0577]]],\n              \n              \n                      [[[ 0.0329, -0.0145, -0.0053],\n                        [ 0.0264,  0.0224,  0.0070],\n                        [-0.0401, -0.0548,  0.0026]],\n              \n                       [[ 0.0244,  0.0094, -0.0386],\n                        [ 0.0350,  0.0106,  0.0272],\n                        [ 0.0173, -0.0449,  0.0127]],\n              \n                       [[-0.0305,  0.0264,  0.0228],\n                        [ 0.0585,  0.0073, -0.0570],\n                        [-0.0515,  0.0477,  0.0081]],\n              \n                       ...,\n              \n                       [[-0.0014, -0.0450, -0.0103],\n                        [-0.0048,  0.0037,  0.0291],\n                        [ 0.0549, -0.0481,  0.0265]],\n              \n                       [[ 0.0583, -0.0363, -0.0222],\n                        [ 0.0433, -0.0356, -0.0548],\n                        [ 0.0395,  0.0347,  0.0260]],\n              \n                       [[ 0.0390,  0.0399,  0.0172],\n                        [ 0.0232, -0.0225, -0.0440],\n                        [ 0.0098, -0.0338, -0.0511]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0091, -0.0535, -0.0310],\n                        [-0.0286,  0.0572,  0.0304],\n                        [ 0.0141,  0.0030, -0.0419]],\n              \n                       [[-0.0321, -0.0170, -0.0190],\n                        [ 0.0182,  0.0238,  0.0274],\n                        [-0.0491, -0.0375,  0.0325]],\n              \n                       [[ 0.0051,  0.0425,  0.0583],\n                        [-0.0415, -0.0469,  0.0344],\n                        [ 0.0420,  0.0359,  0.0179]],\n              \n                       ...,\n              \n                       [[-0.0220, -0.0239,  0.0015],\n                        [-0.0216,  0.0470,  0.0284],\n                        [-0.0138,  0.0255,  0.0417]],\n              \n                       [[ 0.0530,  0.0481,  0.0041],\n                        [ 0.0343,  0.0374, -0.0478],\n                        [-0.0545, -0.0521,  0.0038]],\n              \n                       [[-0.0164,  0.0118, -0.0400],\n                        [-0.0503,  0.0076,  0.0550],\n                        [ 0.0132, -0.0279, -0.0409]]],\n              \n              \n                      [[[-0.0213, -0.0485,  0.0441],\n                        [ 0.0203,  0.0500, -0.0297],\n                        [ 0.0517,  0.0110, -0.0489]],\n              \n                       [[-0.0523,  0.0481, -0.0467],\n                        [ 0.0133, -0.0504,  0.0195],\n                        [-0.0432,  0.0032, -0.0318]],\n              \n                       [[ 0.0148, -0.0188,  0.0091],\n                        [-0.0069,  0.0423,  0.0403],\n                        [ 0.0462,  0.0523, -0.0483]],\n              \n                       ...,\n              \n                       [[ 0.0097, -0.0482, -0.0557],\n                        [ 0.0551,  0.0043,  0.0525],\n                        [-0.0551, -0.0504,  0.0133]],\n              \n                       [[ 0.0247,  0.0033,  0.0405],\n                        [ 0.0342,  0.0133,  0.0041],\n                        [-0.0469, -0.0583,  0.0188]],\n              \n                       [[ 0.0517,  0.0228, -0.0042],\n                        [-0.0035, -0.0215, -0.0226],\n                        [ 0.0231,  0.0358,  0.0423]]],\n              \n              \n                      [[[-0.0197,  0.0141, -0.0213],\n                        [-0.0504,  0.0042,  0.0317],\n                        [ 0.0306,  0.0089, -0.0118]],\n              \n                       [[ 0.0093, -0.0313, -0.0518],\n                        [ 0.0525,  0.0504,  0.0045],\n                        [-0.0348, -0.0087, -0.0410]],\n              \n                       [[-0.0542, -0.0005,  0.0554],\n                        [ 0.0263, -0.0218,  0.0008],\n                        [-0.0525, -0.0520, -0.0582]],\n              \n                       ...,\n              \n                       [[-0.0109,  0.0370,  0.0416],\n                        [ 0.0005, -0.0202, -0.0146],\n                        [ 0.0190, -0.0275,  0.0478]],\n              \n                       [[ 0.0297,  0.0242, -0.0551],\n                        [ 0.0079, -0.0243, -0.0139],\n                        [ 0.0292, -0.0032,  0.0137]],\n              \n                       [[-0.0005, -0.0246, -0.0134],\n                        [-0.0489, -0.0166, -0.0169],\n                        [ 0.0230,  0.0463, -0.0037]]]], device='cuda:0')),\n             ('conv2.0.bias',\n              tensor([ 0.0420, -0.0370, -0.0576,  0.0043,  0.0015,  0.0366, -0.0030, -0.0025,\n                      -0.0172,  0.0415, -0.0052,  0.0444, -0.0114,  0.0144,  0.0065,  0.0561,\n                      -0.0109, -0.0527, -0.0207, -0.0334,  0.0469,  0.0223, -0.0299, -0.0507,\n                       0.0422,  0.0424,  0.0237,  0.0334, -0.0377, -0.0018,  0.0191,  0.0436],\n                     device='cuda:0')),\n             ('conv2.2.weight',\n              tensor([[[[ 1.7357e-02, -2.6854e-02, -4.2758e-02],\n                        [ 5.3192e-02,  4.3668e-03, -2.6304e-03],\n                        [-2.5591e-02, -4.7469e-02,  2.5486e-02]],\n              \n                       [[-2.6409e-02, -1.8676e-02,  1.2110e-02],\n                        [ 2.9048e-02,  4.3502e-03,  1.2345e-02],\n                        [-4.3958e-02, -1.6507e-02, -3.5387e-02]],\n              \n                       [[-7.2599e-03,  3.0330e-02, -3.3335e-02],\n                        [ 2.5341e-02, -1.2013e-02, -1.0272e-02],\n                        [ 2.9166e-03,  1.5133e-02,  7.9722e-04]],\n              \n                       ...,\n              \n                       [[-3.0715e-02, -4.5693e-02, -2.0429e-02],\n                        [-2.1028e-02, -5.8731e-02,  5.1841e-02],\n                        [-2.2672e-02,  2.1338e-02, -4.3603e-02]],\n              \n                       [[ 5.4890e-02,  4.2519e-03,  1.7385e-02],\n                        [-3.9264e-02,  3.0646e-03,  1.2356e-02],\n                        [ 6.3747e-03,  5.7935e-02, -2.5932e-02]],\n              \n                       [[-4.9929e-02, -5.1403e-02,  5.8917e-02],\n                        [-4.5181e-02,  2.1130e-02, -9.7128e-03],\n                        [-2.5762e-03,  1.0575e-02, -1.9632e-02]]],\n              \n              \n                      [[[ 1.4895e-02, -1.4424e-02, -2.1455e-02],\n                        [ 3.6862e-02,  1.7406e-02, -5.1340e-02],\n                        [-2.3613e-02, -4.6745e-02,  4.2186e-02]],\n              \n                       [[ 2.4339e-02,  3.5123e-02, -2.4025e-02],\n                        [ 8.1095e-03, -5.6267e-02, -3.4033e-02],\n                        [-3.2321e-02, -3.1037e-02, -3.2797e-02]],\n              \n                       [[ 2.0706e-02, -4.9490e-02,  4.8934e-02],\n                        [-8.9307e-03, -3.8820e-02, -1.2900e-02],\n                        [-1.7233e-02, -3.8492e-02, -2.1764e-02]],\n              \n                       ...,\n              \n                       [[-7.0494e-03, -2.6016e-02,  3.0780e-02],\n                        [-2.1736e-02, -3.3774e-02,  1.5679e-02],\n                        [-1.0011e-02, -5.5824e-02,  2.7131e-02]],\n              \n                       [[-3.2294e-02,  1.7820e-02, -6.4517e-03],\n                        [ 9.2842e-03,  5.0304e-02, -8.1521e-03],\n                        [ 1.1980e-02, -4.7030e-02,  1.4843e-02]],\n              \n                       [[-3.7236e-02,  2.7234e-02, -2.8376e-02],\n                        [-5.8060e-02, -2.0999e-02, -2.8174e-02],\n                        [ 2.4884e-02,  4.5286e-02, -2.2160e-03]]],\n              \n              \n                      [[[ 2.6551e-02, -3.9817e-03,  4.8522e-02],\n                        [-7.7016e-04, -3.6759e-02,  4.6764e-02],\n                        [-4.6076e-02,  5.1630e-02,  2.1577e-02]],\n              \n                       [[ 5.0047e-02, -2.9209e-02,  3.9385e-02],\n                        [-7.8573e-03, -3.7312e-02,  3.7546e-02],\n                        [ 3.2153e-02,  1.1796e-02, -1.6134e-02]],\n              \n                       [[ 4.8793e-02,  4.1004e-03, -4.8945e-03],\n                        [ 9.3771e-03, -3.8039e-02, -3.4578e-02],\n                        [ 3.2302e-02,  2.4713e-03,  3.7773e-02]],\n              \n                       ...,\n              \n                       [[-4.5528e-03,  3.4371e-02, -5.7255e-04],\n                        [-1.0828e-02, -4.1399e-03,  2.6131e-02],\n                        [-1.9925e-02, -2.1838e-02, -2.6008e-02]],\n              \n                       [[-4.5738e-02,  9.9376e-03, -5.1182e-03],\n                        [-4.0113e-02, -2.4021e-02,  3.4040e-02],\n                        [-4.6521e-02,  3.8015e-02, -3.9748e-02]],\n              \n                       [[ 5.2174e-02, -5.0036e-02,  5.7655e-02],\n                        [ 3.3300e-02,  4.0593e-02, -3.1349e-03],\n                        [ 3.6471e-02, -3.7978e-02, -1.8914e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-3.5962e-02, -8.4404e-03,  2.6609e-02],\n                        [-4.3019e-02, -5.0007e-03,  4.1172e-02],\n                        [-1.0909e-02, -5.6315e-02, -1.5305e-02]],\n              \n                       [[ 2.0890e-02, -1.8690e-02, -1.9982e-02],\n                        [-1.3525e-02,  2.8199e-02,  5.3664e-02],\n                        [ 5.3352e-03,  1.4802e-02,  1.6731e-02]],\n              \n                       [[-2.0027e-02,  4.9408e-02, -4.1734e-02],\n                        [ 2.9621e-03, -4.6991e-03,  3.7221e-02],\n                        [ 2.0128e-02, -4.4666e-02,  5.2676e-02]],\n              \n                       ...,\n              \n                       [[-2.9167e-02,  3.3491e-02,  5.5904e-02],\n                        [ 5.3262e-02, -3.6594e-02, -3.9194e-03],\n                        [-2.1444e-02,  2.6733e-02,  1.2977e-02]],\n              \n                       [[ 1.1441e-02, -4.1682e-02,  5.4020e-02],\n                        [ 3.8118e-02, -3.6735e-02,  1.9404e-02],\n                        [ 7.2893e-04,  2.3570e-02,  4.1464e-02]],\n              \n                       [[ 1.2129e-03,  5.4353e-02,  3.9610e-02],\n                        [-3.1220e-03,  5.8246e-02, -2.0695e-02],\n                        [-4.9239e-02, -3.9724e-02, -3.7460e-02]]],\n              \n              \n                      [[[ 5.3306e-02,  2.3760e-02, -4.5427e-02],\n                        [ 5.7061e-02, -3.4720e-02,  1.5946e-06],\n                        [ 9.5133e-03,  4.6664e-02,  2.9486e-02]],\n              \n                       [[ 4.0255e-02,  8.2550e-03,  1.7619e-02],\n                        [-5.3124e-02, -4.8975e-02,  4.1367e-02],\n                        [ 4.9558e-02, -5.6709e-02,  3.3567e-02]],\n              \n                       [[ 4.6728e-02, -3.8028e-02, -4.7194e-02],\n                        [ 2.0204e-02, -1.7227e-03, -4.0892e-02],\n                        [-7.7420e-03, -2.6174e-02, -1.2155e-02]],\n              \n                       ...,\n              \n                       [[-6.8105e-04, -2.5732e-04,  4.2219e-02],\n                        [-8.9402e-03, -5.7800e-02, -2.4543e-02],\n                        [-5.7411e-02, -4.1788e-02, -7.7193e-03]],\n              \n                       [[ 4.5741e-02, -4.9110e-04, -4.4397e-02],\n                        [-5.0074e-02,  4.3274e-02, -5.8569e-02],\n                        [ 1.5225e-03, -1.6162e-02,  1.6987e-02]],\n              \n                       [[-5.2231e-03,  3.1497e-02,  7.3569e-03],\n                        [-5.1673e-02, -2.0066e-02,  4.3682e-02],\n                        [ 3.3393e-02, -1.1965e-02, -2.6387e-02]]],\n              \n              \n                      [[[ 2.4821e-02,  3.7624e-02, -5.1354e-02],\n                        [-4.5319e-02,  2.8038e-02, -5.8842e-02],\n                        [ 1.1741e-02, -5.3346e-02,  5.6383e-02]],\n              \n                       [[-4.8928e-02, -2.3546e-03,  5.6247e-02],\n                        [-3.3812e-03, -3.7512e-02,  1.4605e-02],\n                        [-5.6080e-02, -8.5762e-03,  4.0242e-02]],\n              \n                       [[-3.6878e-02, -8.5065e-03,  1.4408e-02],\n                        [-2.6518e-02, -5.6055e-02,  2.1446e-02],\n                        [-4.0248e-02,  1.7220e-02, -1.4885e-02]],\n              \n                       ...,\n              \n                       [[ 1.7931e-02, -4.5684e-02,  8.0094e-03],\n                        [ 2.5370e-02,  3.6397e-02, -9.3424e-03],\n                        [ 5.6158e-02, -5.2128e-02, -9.2193e-03]],\n              \n                       [[ 3.2010e-02,  1.9979e-02, -5.1390e-02],\n                        [ 2.7565e-02,  3.8520e-02,  3.7902e-03],\n                        [-1.6709e-02, -5.6524e-02,  4.6573e-03]],\n              \n                       [[ 7.3883e-04, -1.0191e-02, -5.2013e-03],\n                        [ 5.6183e-02, -9.7102e-03,  2.7414e-02],\n                        [ 4.1389e-02, -1.8844e-02,  4.8252e-02]]]], device='cuda:0')),\n             ('conv2.2.bias',\n              tensor([-0.0431,  0.0479,  0.0366,  0.0500, -0.0346, -0.0055, -0.0201, -0.0061,\n                      -0.0544,  0.0213, -0.0247, -0.0553,  0.0461, -0.0555, -0.0501, -0.0217,\n                       0.0378,  0.0490,  0.0315,  0.0252,  0.0395, -0.0067,  0.0541,  0.0122,\n                      -0.0195,  0.0178, -0.0444, -0.0572,  0.0466, -0.0364,  0.0309,  0.0580],\n                     device='cuda:0')),\n             ('classifier.1.weight',\n              tensor([[ 0.0017, -0.0101, -0.0056,  ...,  0.0058,  0.0013,  0.0071]],\n                     device='cuda:0')),\n             ('classifier.1.bias', tensor([0.0091], device='cuda:0'))])"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.835214700Z",
     "start_time": "2024-01-23T15:41:04.683311200Z"
    }
   },
   "id": "6f282f395ffce6e",
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0158]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find image dimensions for linear layer\n",
    "model(img.unsqueeze(0).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.847215300Z",
     "start_time": "2024-01-23T15:41:04.836214700Z"
    }
   },
   "id": "1f7714925bcc04ea",
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "def train_epoch(model,data_loader,loss_fn,optimizer,device):\n",
    "    train_loss, train_acc = 0,0\n",
    "    accuracy = Accuracy(task=\"binary\").to(device)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X).squeeze(1)\n",
    "        batch_loss = loss_fn(y_pred, y.float())\n",
    "        train_loss += batch_loss\n",
    "        y_pred = (y_pred > 0.5).long()\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")\n",
    "\n",
    "def test_epoch(model,data_loader,loss,optimizer,device):\n",
    "  test_loss, test_acc = 0, 0\n",
    "  model.eval()\n",
    "  accuracy = Accuracy(task=\"binary\").to(device)\n",
    "  with torch.inference_mode():\n",
    "    for X,y in test_dataloader:\n",
    "      X,y = X.to(device), y.unsqueeze(1).to(device)\n",
    "      test_pred = model(X)\n",
    "      test_loss += loss(test_pred,y.float())\n",
    "      test_pred = (test_pred > 0.5).long()\n",
    "      test_acc +=  accuracy(test_pred, y)\n",
    "    test_loss/=len(data_loader)\n",
    "    test_acc/=len(data_loader)\n",
    "  print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.2f}% \\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:41:04.853890600Z",
     "start_time": "2024-01-23T15:41:04.845214800Z"
    }
   },
   "id": "b1adfc67cf9b99bd",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "621b3bd1e876424baefbff4ae074b6db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.49654 | Train acc: 0.76%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 4\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "    train_epoch(model, train_dataloader, loss, optimizer, device)\n",
    "    test_epoch(model, test_dataloader, loss, optimizer, device)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-23T15:41:04.850214Z"
    }
   },
   "id": "18cefc9e4863a017",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img, l = None, None\n",
    "for images, labels in train_dataloader:\n",
    "    img, l = images[0], labels[0]\n",
    "    break\n",
    "\n",
    "for batch, (X,y) in enumerate(train_dataloader):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1fb9fc8631e28182",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'first_cnn.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "deea04de5a0bbe76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = VictimCNNModelV0(3, 32, 1)  # Initialize a model with the same architecture\n",
    "model.load_state_dict(torch.load('first_cnn.pth'))\n",
    "model.to(device)  # Don't forget to move the model to the device"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "901970a998af0519",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define the transformation\n",
    "transformation = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Load the images from the test folder\n",
    "test_data_dir = \"./test\"  # Replace with your test folder path\n",
    "test_dataset = ImageFolder(root=test_data_dir, transform=transformation)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Load the trained model\n",
    "model = VictimCNNModelV0(3, 32, 1)  # Initialize a model with the same architecture\n",
    "model.load_state_dict(torch.load('first_cnn.pth'))\n",
    "model.to(device)  # Don't forget to move the model to the device\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# Define a function to unnormalize and plot an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Predict the labels for the test images\n",
    "for images, labels in test_dataloader:\n",
    "    images = images.to(device)\n",
    "    outputs = torch.sigmoid(model(images))\n",
    "    predicted = (outputs > 0.5).long()\n",
    "    \n",
    "    # Convert tensors to numpy arrays for visualization\n",
    "    predicted_np = predicted.cpu().numpy()\n",
    "    labels_np = labels.numpy()\n",
    "    \n",
    "    # Plot the images and display the actual and predicted classes\n",
    "    for i in range(len(images)):\n",
    "        print(f\"Actual class: {labels_np[i]} | Predicted class: {predicted_np[i]}\")\n",
    "        imshow(images[i].cpu())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6cde2151b7af0690",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b0d006f4ee4dba81",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "44d0cb165ca1387e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4b828f7ee2350140",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
